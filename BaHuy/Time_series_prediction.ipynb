{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Time series prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzvTnHKaMB-G",
        "colab_type": "text"
      },
      "source": [
        "Time series data: như là một loại dữ liệu thay đổi theo thời gian. VD: nhiệt độ trong 1 ngày, giá cổ phiếu của 1 công ty trong năm,..\n",
        "LSTM có khả năng nắm bắt các mẫu trong dữ liệu chuỗi thời gian và do đó có thể được sử dụng để đưa ra dự đoán về xu hướng dữ liệu trong tương lai.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meGcfOgE8ygO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JqwH3noHYve",
        "colab_type": "code",
        "outputId": "b0945a97-29af-4d04-b9c6-dd8518773f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "sns.get_dataset_names()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/utils.py:384: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 384 of the file /usr/local/lib/python3.6/dist-packages/seaborn/utils.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  gh_list = BeautifulSoup(http)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['anscombe',\n",
              " 'attention',\n",
              " 'brain_networks',\n",
              " 'car_crashes',\n",
              " 'diamonds',\n",
              " 'dots',\n",
              " 'exercise',\n",
              " 'flights',\n",
              " 'fmri',\n",
              " 'gammas',\n",
              " 'iris',\n",
              " 'mpg',\n",
              " 'planets',\n",
              " 'tips',\n",
              " 'titanic']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPWhmL9wMOH9",
        "colab_type": "text"
      },
      "source": [
        "Sử dụng bộ dữ liệu flights trong thư viện Seaborn. Có 144 dòng và 3 cột dữ liệu. Nhiệm vụ là dự đoán số lượng hành khách đã đi trong 12 tháng tiếp theo dựa trên 132 tháng đầu tiên. Như vậy dùng 132 tháng đầu để train model, và đánh giá model bằng 12 tháng cuối."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5J6PmVrHf5l",
        "colab_type": "code",
        "outputId": "a150d253-9200-4f59-896d-fc127bd0bc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "flight_data = sns.load_dataset(\"flights\")\n",
        "flight_data.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>passengers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1949</td>\n",
              "      <td>January</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1949</td>\n",
              "      <td>February</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1949</td>\n",
              "      <td>March</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1949</td>\n",
              "      <td>April</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1949</td>\n",
              "      <td>May</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1949</td>\n",
              "      <td>June</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1949</td>\n",
              "      <td>July</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1949</td>\n",
              "      <td>August</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1949</td>\n",
              "      <td>September</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1949</td>\n",
              "      <td>October</td>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year      month  passengers\n",
              "0  1949    January         112\n",
              "1  1949   February         118\n",
              "2  1949      March         132\n",
              "3  1949      April         129\n",
              "4  1949        May         121\n",
              "5  1949       June         135\n",
              "6  1949       July         148\n",
              "7  1949     August         148\n",
              "8  1949  September         136\n",
              "9  1949    October         119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYzIpIIKHkas",
        "colab_type": "code",
        "outputId": "87147e0b-8d7d-4a0a-b069-7d7c327e980c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "flight_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo4eJ_LNHoTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig_size[0] = 15\n",
        "fig_size[1] = 5\n",
        "plt.rcParams[\"figure.figsize\"] = fig_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0ho3lS5HuC8",
        "colab_type": "code",
        "outputId": "37a99c07-e69b-4900-bfde-b42b2447ec4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "plt.title('Month vs Passenger')\n",
        "plt.ylabel('Total Passengers')\n",
        "plt.xlabel('Months')\n",
        "plt.grid(True)\n",
        "plt.autoscale(axis='x',tight=True)\n",
        "plt.plot(flight_data['passengers'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc69da78668>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAFNCAYAAAC5cXZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ/8PsKHgHZSwv4sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r2BtfxqHv7c",
        "colab_type": "code",
        "outputId": "d062e8ff-aa29-47b1-8c93-0a836b34d9ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Loại của các cột trong tập dữ liệu là object. \n",
        "flight_data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['year', 'month', 'passengers'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U33smigHzvz",
        "colab_type": "code",
        "outputId": "01d5f263-c18a-46db-baa2-56babcde6cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#Bước tiền xử lý đầu tiên thay đổi loại của cột passengers thành float.\n",
        "print(flight_data['passengers'].values)\n",
        "all_data = flight_data['passengers'].values.astype(float)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[112 118 132 129 121 135 148 148 136 119 104 118 115 126 141 135 125 149\n",
            " 170 170 158 133 114 140 145 150 178 163 172 178 199 199 184 162 146 166\n",
            " 171 180 193 181 183 218 230 242 209 191 172 194 196 196 236 235 229 243\n",
            " 264 272 237 211 180 201 204 188 235 227 234 264 302 293 259 229 203 229\n",
            " 242 233 267 269 270 315 364 347 312 274 237 278 284 277 317 313 318 374\n",
            " 413 405 355 306 271 306 315 301 356 348 355 422 465 467 404 347 305 336\n",
            " 340 318 362 348 363 435 491 505 404 359 310 337 360 342 406 396 420 472\n",
            " 548 559 463 407 362 405 417 391 419 461 472 535 622 606 508 461 390 432]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXYorhr1H3bM",
        "colab_type": "code",
        "outputId": "dfba96ed-c186-4ce3-9d65-2755b6e35ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "print(all_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[112. 118. 132. 129. 121. 135. 148. 148. 136. 119. 104. 118. 115. 126.\n",
            " 141. 135. 125. 149. 170. 170. 158. 133. 114. 140. 145. 150. 178. 163.\n",
            " 172. 178. 199. 199. 184. 162. 146. 166. 171. 180. 193. 181. 183. 218.\n",
            " 230. 242. 209. 191. 172. 194. 196. 196. 236. 235. 229. 243. 264. 272.\n",
            " 237. 211. 180. 201. 204. 188. 235. 227. 234. 264. 302. 293. 259. 229.\n",
            " 203. 229. 242. 233. 267. 269. 270. 315. 364. 347. 312. 274. 237. 278.\n",
            " 284. 277. 317. 313. 318. 374. 413. 405. 355. 306. 271. 306. 315. 301.\n",
            " 356. 348. 355. 422. 465. 467. 404. 347. 305. 336. 340. 318. 362. 348.\n",
            " 363. 435. 491. 505. 404. 359. 310. 337. 360. 342. 406. 396. 420. 472.\n",
            " 548. 559. 463. 407. 362. 405. 417. 391. 419. 461. 472. 535. 622. 606.\n",
            " 508. 461. 390. 432.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v07_gqmH6YL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Chia bộ dữ liệu thành tập train (132) và tập test (12) \n",
        "test_data_size = 12\n",
        "\n",
        "train_data = all_data[:-test_data_size]\n",
        "test_data = all_data[-test_data_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6JY2Y4VH9-8",
        "colab_type": "code",
        "outputId": "f8b62e4c-b2d9-4bf0-e9ea-f58b70727347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "132\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnx1I7NTIAgk",
        "colab_type": "code",
        "outputId": "30ab2043-e63e-46ff-8805-4e5261d353f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[417. 391. 419. 461. 472. 535. 622. 606. 508. 461. 390. 432.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYUMsgDPIDmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tổng số hành khách những năm đầu ít hơn nhiều so với những năm sau, chuẩn hóa dữ liệu trong phạm vi -1 và 1.\n",
        "#Chỉ chuẩn hóa trên tập train, nếu dùng trên tập test có khả năng bị rò rỉ 1 số thông tin từ tập train vào tập test. \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "train_data_normalized = scaler.fit_transform(train_data .reshape(-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "146fCVyHIF6E",
        "colab_type": "code",
        "outputId": "a311f648-ecde-44e3-9c40-f4f9b549112f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "print(train_data_normalized[:5])\n",
        "print(train_data_normalized[-5:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.96483516]\n",
            " [-0.93846154]\n",
            " [-0.87692308]\n",
            " [-0.89010989]\n",
            " [-0.92527473]]\n",
            "[[1.        ]\n",
            " [0.57802198]\n",
            " [0.33186813]\n",
            " [0.13406593]\n",
            " [0.32307692]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eR0SvSYIIdE",
        "colab_type": "code",
        "outputId": "321d84fb-f0a4-4753-aefd-c39c32b82a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "#Bước tiếp theo chuyển đổi data sang dạng  tensor.\n",
        "train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1)\n",
        "print(train_data_normalized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066,\n",
            "        -0.8593, -0.9341, -1.0000, -0.9385, -0.9516, -0.9033, -0.8374, -0.8637,\n",
            "        -0.9077, -0.8022, -0.7099, -0.7099, -0.7626, -0.8725, -0.9560, -0.8418,\n",
            "        -0.8198, -0.7978, -0.6747, -0.7407, -0.7011, -0.6747, -0.5824, -0.5824,\n",
            "        -0.6484, -0.7451, -0.8154, -0.7275, -0.7055, -0.6659, -0.6088, -0.6615,\n",
            "        -0.6527, -0.4989, -0.4462, -0.3934, -0.5385, -0.6176, -0.7011, -0.6044,\n",
            "        -0.5956, -0.5956, -0.4198, -0.4242, -0.4505, -0.3890, -0.2967, -0.2615,\n",
            "        -0.4154, -0.5297, -0.6659, -0.5736, -0.5604, -0.6308, -0.4242, -0.4593,\n",
            "        -0.4286, -0.2967, -0.1297, -0.1692, -0.3187, -0.4505, -0.5648, -0.4505,\n",
            "        -0.3934, -0.4330, -0.2835, -0.2747, -0.2703, -0.0725,  0.1429,  0.0681,\n",
            "        -0.0857, -0.2527, -0.4154, -0.2352, -0.2088, -0.2396, -0.0637, -0.0813,\n",
            "        -0.0593,  0.1868,  0.3582,  0.3231,  0.1033, -0.1121, -0.2659, -0.1121,\n",
            "        -0.0725, -0.1341,  0.1077,  0.0725,  0.1033,  0.3978,  0.5868,  0.5956,\n",
            "         0.3187,  0.0681, -0.1165,  0.0198,  0.0374, -0.0593,  0.1341,  0.0725,\n",
            "         0.1385,  0.4549,  0.7011,  0.7626,  0.3187,  0.1209, -0.0945,  0.0242,\n",
            "         0.1253,  0.0462,  0.3275,  0.2835,  0.3890,  0.6176,  0.9516,  1.0000,\n",
            "         0.5780,  0.3319,  0.1341,  0.3231])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcP3buPCIL-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bước tiền xử lý cuối cùng là chuyển train data thành các chuỗi và nhãn tương ứng.\n",
        "#Vì dữ liệu theo hàng tháng nên sử dụng độ dài chuỗi là 12.\n",
        "\n",
        "train_window = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6cKqfOAIOgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Định nghĩ hàm create_inout_sequences nhận dữ liệu thô và trả về  1 list of tuples. \n",
        "#Mỗi bộ, thành phần đầu tiên chứa 12 item tương ứng số hành khách đi trong 12 tháng, thành phần thứ 2 là chứa 1 item của số lượng hành khách trong tháng tiếp theo 12 tháng đó.\n",
        "def create_inout_sequences(input_data, tw):\n",
        "    inout_seq = []\n",
        "    L = len(input_data)\n",
        "    for i in range(L-tw):\n",
        "        train_seq = input_data[i:i+tw]\n",
        "        train_label = input_data[i+tw:i+tw+1]\n",
        "        inout_seq.append((train_seq ,train_label))\n",
        "    return inout_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVBUkobCIRBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tạo chuỗi và nhãn tương ứng cho train data. Nó chứa 120 item, có nghĩa là do train data có 132 item, độ dài chuỗi 12\n",
        "#Thì chuỗi đầu tiên chứa 12 item đầu và item 13 là label cho chuỗi đầu tiên, tương tự chuỗi thứ 2 bắt đầu từ item thứ 2 đến item thứ 13 và item 14 là label cho chuỗi thứ 2, cứ vậy đến hết.\n",
        "train_inout_seq = create_inout_sequences(train_data_normalized, train_window)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHBkrnrZITvz",
        "colab_type": "code",
        "outputId": "51117b7a-49be-43a4-bec2-56d4e5bb3fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "train_inout_seq[:5]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066,\n",
              "          -0.8593, -0.9341, -1.0000, -0.9385]), tensor([-0.9516])),\n",
              " (tensor([-0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593,\n",
              "          -0.9341, -1.0000, -0.9385, -0.9516]),\n",
              "  tensor([-0.9033])),\n",
              " (tensor([-0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341,\n",
              "          -1.0000, -0.9385, -0.9516, -0.9033]), tensor([-0.8374])),\n",
              " (tensor([-0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000,\n",
              "          -0.9385, -0.9516, -0.9033, -0.8374]), tensor([-0.8637])),\n",
              " (tensor([-0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000, -0.9385,\n",
              "          -0.9516, -0.9033, -0.8374, -0.8637]), tensor([-0.9077]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXJ7twSWIXUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input_size: Tương ứng với số lượng feature trong đầu vào. Mặc dù độ dài chuỗi của là 12, nhưng mỗi tháng chỉ có 1 giá trị tức là tổng số hành khách, do đó kích thước đầu vào sẽ là 1.\n",
        "#output_size: vì muốn dự đoán số lượng hành khách trong 1 tháng trong tương lai, kích thước đầu ra sẽ là 1.\n",
        "#Thuật toán LSTM chấp nhận ba đầu vào: previous hidden_cell,  previous cell state và đầu vào hiện tại. Các hidden_cell  chứa các trạng thái ẩn và tế bào trước. Các biến lstm và linear lớp được sử dụng để tạo LSTM và các lớp tuyến tính.\n",
        "#Bên trong phương thức forward, input_seq được truyền dưới dạng tham số, lần đầu tiên được truyền qua lớp lstm. Đầu ra của lớp lstm là the hidden and cell states ở bước thời gian hiện tại, cùng với đầu ra. Đầu ra từ lớp lstm được truyền cho lớp linear. Số lượng hành khách dự đoán được lưu trữ trong mục cuối cùng của danh sách predictions.\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1): #\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
        "\n",
        "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
        "\n",
        "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
        "                            torch.zeros(1,1,self.hidden_layer_size))\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
        "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
        "        return predictions[-1] #Lấy thằng cuối cùng "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh5GmhbHIbD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTM()\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRjhxy5oIeCE",
        "colab_type": "code",
        "outputId": "ed0b4bee-4240-424b-eed3-5d8363eed564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM(\n",
            "  (lstm): LSTM(1, 100)\n",
            "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKa3VsXT_8r2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1): #\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
        "\n",
        "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
        "\n",
        "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
        "                            torch.zeros(1,1,self.hidden_layer_size))\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
        "        print(\"lstm_out_before--------\")\n",
        "        print(lstm_out.size())\n",
        "        print(lstm_out)\n",
        "        predictions = self.linear(lstm_out)\n",
        "        print(\"Predictions----------------------\")\n",
        "        print(predictions.size())\n",
        "        print(predictions)\n",
        "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
        "        print(\"Predictions----------------------\")\n",
        "        print(predictions.size())\n",
        "        print(predictions)\n",
        "        print(\"lstm_out----------------------\")\n",
        "        print(lstm_out.size())\n",
        "        print(lstm_out)\n",
        "        print(\"hidden_cell----------------------\")\n",
        "        print(self.hidden_cell)\n",
        "        return predictions[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znl0ugUU_gK-",
        "colab_type": "code",
        "outputId": "beb99c26-97e2-4599-ce83-889eec37cc49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " #test\n",
        " model = LSTM()\n",
        " for seq, labels in train_inout_seq[0:1]:\n",
        "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
        "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
        "        print(seq)\n",
        "        pred = model(seq)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066,\n",
            "        -0.8593, -0.9341, -1.0000, -0.9385])\n",
            "lstm_out_before--------\n",
            "torch.Size([12, 1, 100])\n",
            "tensor([[[ 0.0136,  0.0091, -0.0156,  ..., -0.0231,  0.0145,  0.0378]],\n",
            "\n",
            "        [[ 0.0222,  0.0137, -0.0259,  ..., -0.0379,  0.0154,  0.0621]],\n",
            "\n",
            "        [[ 0.0275,  0.0161, -0.0319,  ..., -0.0464,  0.0113,  0.0753]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.0327,  0.0226, -0.0421,  ..., -0.0575, -0.0071,  0.0948]],\n",
            "\n",
            "        [[ 0.0317,  0.0245, -0.0439,  ..., -0.0583, -0.0077,  0.0980]],\n",
            "\n",
            "        [[ 0.0318,  0.0247, -0.0441,  ..., -0.0581, -0.0083,  0.0978]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Predictions----------------------\n",
            "torch.Size([12, 1, 1])\n",
            "tensor([[[-0.0286]],\n",
            "\n",
            "        [[-0.0245]],\n",
            "\n",
            "        [[-0.0214]],\n",
            "\n",
            "        [[-0.0186]],\n",
            "\n",
            "        [[-0.0163]],\n",
            "\n",
            "        [[-0.0152]],\n",
            "\n",
            "        [[-0.0146]],\n",
            "\n",
            "        [[-0.0141]],\n",
            "\n",
            "        [[-0.0133]],\n",
            "\n",
            "        [[-0.0124]],\n",
            "\n",
            "        [[-0.0116]],\n",
            "\n",
            "        [[-0.0118]]], grad_fn=<AddBackward0>)\n",
            "Predictions----------------------\n",
            "torch.Size([12, 1])\n",
            "tensor([[-0.0286],\n",
            "        [-0.0245],\n",
            "        [-0.0214],\n",
            "        [-0.0186],\n",
            "        [-0.0163],\n",
            "        [-0.0152],\n",
            "        [-0.0146],\n",
            "        [-0.0141],\n",
            "        [-0.0133],\n",
            "        [-0.0124],\n",
            "        [-0.0116],\n",
            "        [-0.0118]], grad_fn=<AddmmBackward>)\n",
            "lstm_out----------------------\n",
            "torch.Size([12, 1, 100])\n",
            "tensor([[[ 0.0136,  0.0091, -0.0156,  ..., -0.0231,  0.0145,  0.0378]],\n",
            "\n",
            "        [[ 0.0222,  0.0137, -0.0259,  ..., -0.0379,  0.0154,  0.0621]],\n",
            "\n",
            "        [[ 0.0275,  0.0161, -0.0319,  ..., -0.0464,  0.0113,  0.0753]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.0327,  0.0226, -0.0421,  ..., -0.0575, -0.0071,  0.0948]],\n",
            "\n",
            "        [[ 0.0317,  0.0245, -0.0439,  ..., -0.0583, -0.0077,  0.0980]],\n",
            "\n",
            "        [[ 0.0318,  0.0247, -0.0441,  ..., -0.0581, -0.0083,  0.0978]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "hidden_cell----------------------\n",
            "(tensor([[[ 0.0318,  0.0247, -0.0441,  0.0045,  0.0063, -0.0236,  0.0463,\n",
            "           0.0323,  0.0124,  0.0553,  0.0988,  0.0466, -0.0863,  0.0347,\n",
            "           0.0639,  0.0033, -0.0237,  0.0447,  0.0677, -0.0043,  0.0031,\n",
            "          -0.0778,  0.0398,  0.0506, -0.0512,  0.0043, -0.0814,  0.0647,\n",
            "          -0.0079,  0.0030, -0.0922, -0.0693,  0.0665,  0.0650,  0.0434,\n",
            "          -0.0979,  0.0233,  0.0638,  0.0288,  0.0429, -0.0363, -0.0313,\n",
            "           0.0403,  0.0662,  0.0868,  0.0343, -0.0015,  0.0895, -0.0182,\n",
            "          -0.0183,  0.0468, -0.0083, -0.0092, -0.0735, -0.0182, -0.0697,\n",
            "          -0.0404,  0.0019, -0.0424, -0.0479,  0.0704, -0.0744, -0.0007,\n",
            "          -0.0275, -0.0734, -0.0048,  0.0063, -0.0122,  0.0610,  0.0272,\n",
            "           0.0241, -0.0040,  0.0182, -0.0722,  0.0448, -0.0147, -0.1001,\n",
            "           0.0373,  0.0132, -0.0615,  0.0433,  0.0074, -0.0085, -0.0557,\n",
            "           0.0740,  0.0176, -0.0285,  0.0237,  0.0019,  0.1147,  0.0725,\n",
            "          -0.0113,  0.0188, -0.0476,  0.0170,  0.0758,  0.0781, -0.0581,\n",
            "          -0.0083,  0.0978]]], grad_fn=<StackBackward>), tensor([[[ 0.0637,  0.0485, -0.0919,  0.0090,  0.0122, -0.0455,  0.0858,\n",
            "           0.0657,  0.0243,  0.1082,  0.1900,  0.0935, -0.1747,  0.0641,\n",
            "           0.1422,  0.0067, -0.0468,  0.0903,  0.1341, -0.0091,  0.0063,\n",
            "          -0.1558,  0.0753,  0.0970, -0.0991,  0.0085, -0.1556,  0.1144,\n",
            "          -0.0173,  0.0055, -0.1815, -0.1413,  0.1457,  0.1306,  0.0870,\n",
            "          -0.2144,  0.0454,  0.1301,  0.0593,  0.0933, -0.0758, -0.0631,\n",
            "           0.0805,  0.1319,  0.1736,  0.0681, -0.0028,  0.1627, -0.0344,\n",
            "          -0.0355,  0.1033, -0.0149, -0.0179, -0.1649, -0.0383, -0.1366,\n",
            "          -0.0799,  0.0037, -0.0804, -0.0939,  0.1390, -0.1380, -0.0013,\n",
            "          -0.0529, -0.1416, -0.0098,  0.0117, -0.0257,  0.1214,  0.0563,\n",
            "           0.0449, -0.0081,  0.0361, -0.1501,  0.0845, -0.0272, -0.1954,\n",
            "           0.0714,  0.0248, -0.1268,  0.0847,  0.0149, -0.0171, -0.1171,\n",
            "           0.1547,  0.0339, -0.0597,  0.0457,  0.0040,  0.2356,  0.1496,\n",
            "          -0.0240,  0.0399, -0.0956,  0.0334,  0.1689,  0.1496, -0.1192,\n",
            "          -0.0162,  0.1912]]], grad_fn=<StackBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si1sAvoKIn58",
        "colab_type": "code",
        "outputId": "842bf84c-890b-47ea-f373-a0cff82f4499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 150\n",
        "\n",
        "for i in range(epochs):\n",
        "    for seq, labels in train_inout_seq:\n",
        "        optimizer.zero_grad()\n",
        "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
        "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
        "\n",
        "        y_pred = model(seq)\n",
        "\n",
        "        single_loss = loss_function(y_pred, labels)\n",
        "        single_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if i%25 == 1:\n",
        "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
        "\n",
        "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [ 0.3079],\n",
            "        [ 0.3175],\n",
            "        [ 0.4250],\n",
            "        [ 0.3753],\n",
            "        [ 0.1890],\n",
            "        [ 0.1371]], grad_fn=<AddmmBackward>)\n",
            "tensor([[0.0230],\n",
            "        [0.1143],\n",
            "        [0.1043],\n",
            "        [0.3592],\n",
            "        [0.3832],\n",
            "        [0.4244],\n",
            "        [0.4737],\n",
            "        [0.5396],\n",
            "        [0.3908],\n",
            "        [0.1038],\n",
            "        [0.0385],\n",
            "        [0.2641]], grad_fn=<AddmmBackward>)\n",
            "epoch:  76 loss: 0.00347305\n",
            "tensor([[-0.7078],\n",
            "        [-0.7139],\n",
            "        [-0.6966],\n",
            "        [-0.7547],\n",
            "        [-0.8035],\n",
            "        [-0.7468],\n",
            "        [-0.6044],\n",
            "        [-0.4610],\n",
            "        [-0.5403],\n",
            "        [-0.7201],\n",
            "        [-0.7425],\n",
            "        [-0.7556]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6914],\n",
            "        [-0.6712],\n",
            "        [-0.7170],\n",
            "        [-0.7774],\n",
            "        [-0.7691],\n",
            "        [-0.7228],\n",
            "        [-0.6090],\n",
            "        [-0.5100],\n",
            "        [-0.6279],\n",
            "        [-0.7492],\n",
            "        [-0.6883],\n",
            "        [-0.7894]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6495],\n",
            "        [-0.6909],\n",
            "        [-0.7516],\n",
            "        [-0.7422],\n",
            "        [-0.7504],\n",
            "        [-0.7253],\n",
            "        [-0.6503],\n",
            "        [-0.5923],\n",
            "        [-0.7178],\n",
            "        [-0.6517],\n",
            "        [-0.7673],\n",
            "        [-0.7549]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6646],\n",
            "        [-0.7311],\n",
            "        [-0.7134],\n",
            "        [-0.7243],\n",
            "        [-0.7537],\n",
            "        [-0.7618],\n",
            "        [-0.7166],\n",
            "        [-0.6966],\n",
            "        [-0.6602],\n",
            "        [-0.7258],\n",
            "        [-0.7730],\n",
            "        [-0.7401]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6978],\n",
            "        [-0.6945],\n",
            "        [-0.6861],\n",
            "        [-0.7360],\n",
            "        [-0.7956],\n",
            "        [-0.8345],\n",
            "        [-0.8157],\n",
            "        [-0.6814],\n",
            "        [-0.7283],\n",
            "        [-0.7402],\n",
            "        [-0.7482],\n",
            "        [-0.7811]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6579],\n",
            "        [-0.6607],\n",
            "        [-0.7012],\n",
            "        [-0.7823],\n",
            "        [-0.8723],\n",
            "        [-0.9303],\n",
            "        [-0.8254],\n",
            "        [-0.7783],\n",
            "        [-0.6879],\n",
            "        [-0.6758],\n",
            "        [-0.7586],\n",
            "        [-0.8101]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6197],\n",
            "        [-0.6719],\n",
            "        [-0.7557],\n",
            "        [-0.8528],\n",
            "        [-0.9545],\n",
            "        [-0.9293],\n",
            "        [-0.9121],\n",
            "        [-0.7475],\n",
            "        [-0.6009],\n",
            "        [-0.6653],\n",
            "        [-0.7850],\n",
            "        [-0.7184]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6252],\n",
            "        [-0.7286],\n",
            "        [-0.8302],\n",
            "        [-0.9253],\n",
            "        [-0.9469],\n",
            "        [-0.9938],\n",
            "        [-0.8862],\n",
            "        [-0.6833],\n",
            "        [-0.5936],\n",
            "        [-0.7135],\n",
            "        [-0.6631],\n",
            "        [-0.6781]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6725],\n",
            "        [-0.8074],\n",
            "        [-0.8989],\n",
            "        [-0.9071],\n",
            "        [-1.0007],\n",
            "        [-0.9722],\n",
            "        [-0.8417],\n",
            "        [-0.6793],\n",
            "        [-0.6311],\n",
            "        [-0.6078],\n",
            "        [-0.6135],\n",
            "        [-0.7117]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7379],\n",
            "        [-0.8814],\n",
            "        [-0.8624],\n",
            "        [-0.9519],\n",
            "        [-0.9803],\n",
            "        [-0.9461],\n",
            "        [-0.8538],\n",
            "        [-0.7016],\n",
            "        [-0.5274],\n",
            "        [-0.5471],\n",
            "        [-0.6922],\n",
            "        [-0.7592]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7978],\n",
            "        [-0.8480],\n",
            "        [-0.8923],\n",
            "        [-0.9349],\n",
            "        [-0.9593],\n",
            "        [-0.9788],\n",
            "        [-0.8900],\n",
            "        [-0.5996],\n",
            "        [-0.4738],\n",
            "        [-0.6199],\n",
            "        [-0.7688],\n",
            "        [-0.8670]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7570],\n",
            "        [-0.8734],\n",
            "        [-0.8693],\n",
            "        [-0.9049],\n",
            "        [-0.9923],\n",
            "        [-1.0246],\n",
            "        [-0.8213],\n",
            "        [-0.5625],\n",
            "        [-0.5179],\n",
            "        [-0.7026],\n",
            "        [-0.8631],\n",
            "        [-0.9406]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7735],\n",
            "        [-0.8441],\n",
            "        [-0.8272],\n",
            "        [-0.9358],\n",
            "        [-1.0282],\n",
            "        [-0.9564],\n",
            "        [-0.7738],\n",
            "        [-0.5792],\n",
            "        [-0.5710],\n",
            "        [-0.8183],\n",
            "        [-0.8863],\n",
            "        [-0.8630]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7387],\n",
            "        [-0.7912],\n",
            "        [-0.8571],\n",
            "        [-0.9680],\n",
            "        [-0.9625],\n",
            "        [-0.9108],\n",
            "        [-0.7834],\n",
            "        [-0.6150],\n",
            "        [-0.6987],\n",
            "        [-0.8711],\n",
            "        [-0.7680],\n",
            "        [-0.8966]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6868],\n",
            "        [-0.8139],\n",
            "        [-0.8980],\n",
            "        [-0.8896],\n",
            "        [-0.9077],\n",
            "        [-0.8966],\n",
            "        [-0.7988],\n",
            "        [-0.7233],\n",
            "        [-0.8232],\n",
            "        [-0.7049],\n",
            "        [-0.8624],\n",
            "        [-0.8790]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7072],\n",
            "        [-0.8521],\n",
            "        [-0.8053],\n",
            "        [-0.8241],\n",
            "        [-0.8777],\n",
            "        [-0.8894],\n",
            "        [-0.8564],\n",
            "        [-0.8247],\n",
            "        [-0.6949],\n",
            "        [-0.7847],\n",
            "        [-0.8823],\n",
            "        [-0.7932]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7413],\n",
            "        [-0.7569],\n",
            "        [-0.7228],\n",
            "        [-0.8035],\n",
            "        [-0.8764],\n",
            "        [-0.9525],\n",
            "        [-0.9407],\n",
            "        [-0.7286],\n",
            "        [-0.7472],\n",
            "        [-0.8332],\n",
            "        [-0.7589],\n",
            "        [-0.8264]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6508],\n",
            "        [-0.6582],\n",
            "        [-0.7051],\n",
            "        [-0.8044],\n",
            "        [-0.9365],\n",
            "        [-1.0214],\n",
            "        [-0.8688],\n",
            "        [-0.7900],\n",
            "        [-0.7172],\n",
            "        [-0.5966],\n",
            "        [-0.7183],\n",
            "        [-0.6955]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5710],\n",
            "        [-0.6429],\n",
            "        [-0.7348],\n",
            "        [-0.8736],\n",
            "        [-0.9988],\n",
            "        [-0.9397],\n",
            "        [-0.9027],\n",
            "        [-0.7433],\n",
            "        [-0.4566],\n",
            "        [-0.5402],\n",
            "        [-0.6347],\n",
            "        [-0.6556]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5672],\n",
            "        [-0.6818],\n",
            "        [-0.8212],\n",
            "        [-0.9364],\n",
            "        [-0.9199],\n",
            "        [-0.9470],\n",
            "        [-0.8444],\n",
            "        [-0.5219],\n",
            "        [-0.4166],\n",
            "        [-0.4911],\n",
            "        [-0.5852],\n",
            "        [-0.5840]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6072],\n",
            "        [-0.7757],\n",
            "        [-0.8879],\n",
            "        [-0.8511],\n",
            "        [-0.9227],\n",
            "        [-0.8949],\n",
            "        [-0.6687],\n",
            "        [-0.4839],\n",
            "        [-0.3114],\n",
            "        [-0.5168],\n",
            "        [-0.5026],\n",
            "        [-0.6156]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6940],\n",
            "        [-0.8514],\n",
            "        [-0.7854],\n",
            "        [-0.8506],\n",
            "        [-0.8779],\n",
            "        [-0.7612],\n",
            "        [-0.6553],\n",
            "        [-0.3347],\n",
            "        [-0.3399],\n",
            "        [-0.4474],\n",
            "        [-0.5567],\n",
            "        [-0.6705]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7599],\n",
            "        [-0.7524],\n",
            "        [-0.7664],\n",
            "        [-0.8187],\n",
            "        [-0.7647],\n",
            "        [-0.7830],\n",
            "        [-0.5377],\n",
            "        [-0.3125],\n",
            "        [-0.2773],\n",
            "        [-0.4836],\n",
            "        [-0.6486],\n",
            "        [-0.7365]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6670],\n",
            "        [-0.7254],\n",
            "        [-0.7416],\n",
            "        [-0.7073],\n",
            "        [-0.7968],\n",
            "        [-0.7021],\n",
            "        [-0.5312],\n",
            "        [-0.2264],\n",
            "        [-0.3003],\n",
            "        [-0.5929],\n",
            "        [-0.7124],\n",
            "        [-0.7636]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6484],\n",
            "        [-0.7029],\n",
            "        [-0.6342],\n",
            "        [-0.7490],\n",
            "        [-0.7254],\n",
            "        [-0.6779],\n",
            "        [-0.4250],\n",
            "        [-0.2492],\n",
            "        [-0.3950],\n",
            "        [-0.6848],\n",
            "        [-0.7059],\n",
            "        [-0.6960]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6299],\n",
            "        [-0.5921],\n",
            "        [-0.6851],\n",
            "        [-0.6918],\n",
            "        [-0.7067],\n",
            "        [-0.5822],\n",
            "        [-0.4325],\n",
            "        [-0.3081],\n",
            "        [-0.5139],\n",
            "        [-0.6951],\n",
            "        [-0.6105],\n",
            "        [-0.6989]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5281],\n",
            "        [-0.6390],\n",
            "        [-0.6424],\n",
            "        [-0.6680],\n",
            "        [-0.6200],\n",
            "        [-0.5758],\n",
            "        [-0.4661],\n",
            "        [-0.4226],\n",
            "        [-0.6036],\n",
            "        [-0.5414],\n",
            "        [-0.6577],\n",
            "        [-0.6592]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5807],\n",
            "        [-0.6068],\n",
            "        [-0.6200],\n",
            "        [-0.5906],\n",
            "        [-0.6043],\n",
            "        [-0.5815],\n",
            "        [-0.5306],\n",
            "        [-0.5369],\n",
            "        [-0.5081],\n",
            "        [-0.5878],\n",
            "        [-0.6613],\n",
            "        [-0.6096]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5476],\n",
            "        [-0.5797],\n",
            "        [-0.5370],\n",
            "        [-0.5787],\n",
            "        [-0.6232],\n",
            "        [-0.6547],\n",
            "        [-0.6346],\n",
            "        [-0.4896],\n",
            "        [-0.5313],\n",
            "        [-0.5994],\n",
            "        [-0.5892],\n",
            "        [-0.6340]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5256],\n",
            "        [-0.4971],\n",
            "        [-0.5312],\n",
            "        [-0.6094],\n",
            "        [-0.6938],\n",
            "        [-0.7358],\n",
            "        [-0.5987],\n",
            "        [-0.5378],\n",
            "        [-0.4830],\n",
            "        [-0.4654],\n",
            "        [-0.5700],\n",
            "        [-0.5860]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4485],\n",
            "        [-0.4878],\n",
            "        [-0.5758],\n",
            "        [-0.6796],\n",
            "        [-0.7631],\n",
            "        [-0.6928],\n",
            "        [-0.6439],\n",
            "        [-0.4920],\n",
            "        [-0.3249],\n",
            "        [-0.4067],\n",
            "        [-0.5380],\n",
            "        [-0.4360]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4474],\n",
            "        [-0.5423],\n",
            "        [-0.6585],\n",
            "        [-0.7447],\n",
            "        [-0.7132],\n",
            "        [-0.7091],\n",
            "        [-0.5865],\n",
            "        [-0.3610],\n",
            "        [-0.2833],\n",
            "        [-0.4151],\n",
            "        [-0.3715],\n",
            "        [-0.4426]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5000],\n",
            "        [-0.6288],\n",
            "        [-0.7224],\n",
            "        [-0.6868],\n",
            "        [-0.7218],\n",
            "        [-0.6574],\n",
            "        [-0.4862],\n",
            "        [-0.3197],\n",
            "        [-0.2554],\n",
            "        [-0.2837],\n",
            "        [-0.3760],\n",
            "        [-0.4625]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5785],\n",
            "        [-0.6960],\n",
            "        [-0.6509],\n",
            "        [-0.6886],\n",
            "        [-0.6770],\n",
            "        [-0.5889],\n",
            "        [-0.4717],\n",
            "        [-0.2515],\n",
            "        [-0.1201],\n",
            "        [-0.2877],\n",
            "        [-0.4345],\n",
            "        [-0.5961]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6354],\n",
            "        [-0.6234],\n",
            "        [-0.6351],\n",
            "        [-0.6491],\n",
            "        [-0.6202],\n",
            "        [-0.6042],\n",
            "        [-0.4228],\n",
            "        [-0.0981],\n",
            "        [-0.1187],\n",
            "        [-0.3226],\n",
            "        [-0.5956],\n",
            "        [-0.6247]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5645],\n",
            "        [-0.6005],\n",
            "        [-0.5975],\n",
            "        [-0.5937],\n",
            "        [-0.6456],\n",
            "        [-0.5781],\n",
            "        [-0.3026],\n",
            "        [-0.0906],\n",
            "        [-0.0670],\n",
            "        [-0.4956],\n",
            "        [-0.6372],\n",
            "        [-0.6119]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5470],\n",
            "        [-0.5659],\n",
            "        [-0.5480],\n",
            "        [-0.6262],\n",
            "        [-0.6206],\n",
            "        [-0.4543],\n",
            "        [-0.2708],\n",
            "        [-0.0152],\n",
            "        [-0.2438],\n",
            "        [-0.5923],\n",
            "        [-0.5625],\n",
            "        [-0.5526]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5154],\n",
            "        [-0.5151],\n",
            "        [-0.5893],\n",
            "        [-0.6078],\n",
            "        [-0.5054],\n",
            "        [-0.4158],\n",
            "        [-0.1841],\n",
            "        [-0.1531],\n",
            "        [-0.3756],\n",
            "        [-0.5632],\n",
            "        [-0.4750],\n",
            "        [-0.5897]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4692],\n",
            "        [-0.5576],\n",
            "        [-0.5806],\n",
            "        [-0.4898],\n",
            "        [-0.4649],\n",
            "        [-0.3257],\n",
            "        [-0.2785],\n",
            "        [-0.2536],\n",
            "        [-0.5064],\n",
            "        [-0.4055],\n",
            "        [-0.5691],\n",
            "        [-0.5827]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5114],\n",
            "        [-0.5520],\n",
            "        [-0.4518],\n",
            "        [-0.4484],\n",
            "        [-0.3741],\n",
            "        [-0.3951],\n",
            "        [-0.3271],\n",
            "        [-0.4440],\n",
            "        [-0.3935],\n",
            "        [-0.5094],\n",
            "        [-0.5875],\n",
            "        [-0.4328]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5031],\n",
            "        [-0.4165],\n",
            "        [-0.4008],\n",
            "        [-0.3688],\n",
            "        [-0.4515],\n",
            "        [-0.4443],\n",
            "        [-0.4954],\n",
            "        [-0.3938],\n",
            "        [-0.4667],\n",
            "        [-0.5535],\n",
            "        [-0.4066],\n",
            "        [-0.4022]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3765],\n",
            "        [-0.3593],\n",
            "        [-0.3361],\n",
            "        [-0.4579],\n",
            "        [-0.5061],\n",
            "        [-0.5779],\n",
            "        [-0.4619],\n",
            "        [-0.4705],\n",
            "        [-0.4789],\n",
            "        [-0.3122],\n",
            "        [-0.3109],\n",
            "        [-0.3028]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3337],\n",
            "        [-0.3109],\n",
            "        [-0.4486],\n",
            "        [-0.5203],\n",
            "        [-0.6109],\n",
            "        [-0.5221],\n",
            "        [-0.5135],\n",
            "        [-0.4565],\n",
            "        [-0.2214],\n",
            "        [-0.1999],\n",
            "        [-0.2791],\n",
            "        [-0.3237]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2907],\n",
            "        [-0.4274],\n",
            "        [-0.5216],\n",
            "        [-0.6138],\n",
            "        [-0.5533],\n",
            "        [-0.5587],\n",
            "        [-0.4918],\n",
            "        [-0.2113],\n",
            "        [-0.1134],\n",
            "        [-0.2046],\n",
            "        [-0.3232],\n",
            "        [-0.2862]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4094],\n",
            "        [-0.5078],\n",
            "        [-0.6090],\n",
            "        [-0.5531],\n",
            "        [-0.5795],\n",
            "        [-0.5341],\n",
            "        [-0.2684],\n",
            "        [-0.1098],\n",
            "        [-0.1077],\n",
            "        [-0.2608],\n",
            "        [-0.2531],\n",
            "        [-0.3278]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4749],\n",
            "        [-0.5862],\n",
            "        [-0.5348],\n",
            "        [-0.5670],\n",
            "        [-0.5660],\n",
            "        [-0.3677],\n",
            "        [-0.2242],\n",
            "        [-0.0588],\n",
            "        [-0.0980],\n",
            "        [-0.1783],\n",
            "        [-0.2918],\n",
            "        [-0.5066]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.4424e-01],\n",
            "        [-5.0890e-01],\n",
            "        [-5.3267e-01],\n",
            "        [-5.5741e-01],\n",
            "        [-4.1760e-01],\n",
            "        [-3.5256e-01],\n",
            "        [-1.7437e-01],\n",
            "        [-2.3709e-04],\n",
            "        [-4.9600e-02],\n",
            "        [-2.0135e-01],\n",
            "        [-5.0044e-01],\n",
            "        [-6.0966e-01]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4663],\n",
            "        [-0.4968],\n",
            "        [-0.5261],\n",
            "        [-0.4096],\n",
            "        [-0.4151],\n",
            "        [-0.3253],\n",
            "        [-0.1138],\n",
            "        [ 0.0606],\n",
            "        [-0.0588],\n",
            "        [-0.4367],\n",
            "        [-0.6172],\n",
            "        [-0.6132]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4599],\n",
            "        [-0.4970],\n",
            "        [-0.3780],\n",
            "        [-0.4103],\n",
            "        [-0.3856],\n",
            "        [-0.2461],\n",
            "        [-0.0228],\n",
            "        [ 0.0483],\n",
            "        [-0.3184],\n",
            "        [-0.5784],\n",
            "        [-0.6063],\n",
            "        [-0.5253]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4610],\n",
            "        [-0.3477],\n",
            "        [-0.3764],\n",
            "        [-0.3948],\n",
            "        [-0.3170],\n",
            "        [-0.1589],\n",
            "        [-0.0102],\n",
            "        [-0.1791],\n",
            "        [-0.4815],\n",
            "        [-0.5839],\n",
            "        [-0.5052],\n",
            "        [-0.5432]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3179],\n",
            "        [-0.3402],\n",
            "        [-0.3803],\n",
            "        [-0.3342],\n",
            "        [-0.2434],\n",
            "        [-0.1383],\n",
            "        [-0.1859],\n",
            "        [-0.3350],\n",
            "        [-0.5696],\n",
            "        [-0.4402],\n",
            "        [-0.5442],\n",
            "        [-0.5853]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3215],\n",
            "        [-0.3622],\n",
            "        [-0.3300],\n",
            "        [-0.2605],\n",
            "        [-0.1961],\n",
            "        [-0.2403],\n",
            "        [-0.3044],\n",
            "        [-0.5253],\n",
            "        [-0.4154],\n",
            "        [-0.5128],\n",
            "        [-0.5931],\n",
            "        [-0.4288]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3434],\n",
            "        [-0.3127],\n",
            "        [-0.2527],\n",
            "        [-0.2165],\n",
            "        [-0.2920],\n",
            "        [-0.3428],\n",
            "        [-0.5072],\n",
            "        [-0.4193],\n",
            "        [-0.4777],\n",
            "        [-0.5949],\n",
            "        [-0.4147],\n",
            "        [-0.4453]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2928],\n",
            "        [-0.2305],\n",
            "        [-0.2085],\n",
            "        [-0.3159],\n",
            "        [-0.3916],\n",
            "        [-0.5316],\n",
            "        [-0.4425],\n",
            "        [-0.4741],\n",
            "        [-0.5712],\n",
            "        [-0.3802],\n",
            "        [-0.3985],\n",
            "        [-0.2601]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2176],\n",
            "        [-0.1936],\n",
            "        [-0.3215],\n",
            "        [-0.4170],\n",
            "        [-0.5562],\n",
            "        [-0.4760],\n",
            "        [-0.4925],\n",
            "        [-0.5473],\n",
            "        [-0.3250],\n",
            "        [-0.3246],\n",
            "        [-0.2079],\n",
            "        [-0.0905]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1896],\n",
            "        [-0.3171],\n",
            "        [-0.4304],\n",
            "        [-0.5671],\n",
            "        [-0.5017],\n",
            "        [-0.5158],\n",
            "        [-0.5447],\n",
            "        [-0.2879],\n",
            "        [-0.2550],\n",
            "        [-0.1660],\n",
            "        [-0.1237],\n",
            "        [-0.0900]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3163],\n",
            "        [-0.4295],\n",
            "        [-0.5719],\n",
            "        [-0.5137],\n",
            "        [-0.5361],\n",
            "        [-0.5598],\n",
            "        [-0.2900],\n",
            "        [-0.2147],\n",
            "        [-0.1113],\n",
            "        [-0.1138],\n",
            "        [-0.1085],\n",
            "        [-0.3088]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4115],\n",
            "        [-0.5569],\n",
            "        [-0.5089],\n",
            "        [-0.5351],\n",
            "        [-0.5872],\n",
            "        [-0.3610],\n",
            "        [-0.2777],\n",
            "        [-0.0601],\n",
            "        [ 0.0084],\n",
            "        [-0.0185],\n",
            "        [-0.3000],\n",
            "        [-0.5605]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5235],\n",
            "        [-0.4854],\n",
            "        [-0.5066],\n",
            "        [-0.5832],\n",
            "        [-0.4096],\n",
            "        [-0.3862],\n",
            "        [-0.1532],\n",
            "        [ 0.0878],\n",
            "        [ 0.1203],\n",
            "        [-0.2011],\n",
            "        [-0.5549],\n",
            "        [-0.5986]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4467],\n",
            "        [-0.4660],\n",
            "        [-0.5552],\n",
            "        [-0.4063],\n",
            "        [-0.4484],\n",
            "        [-0.3039],\n",
            "        [-0.0293],\n",
            "        [ 0.2478],\n",
            "        [-0.0190],\n",
            "        [-0.4957],\n",
            "        [-0.5729],\n",
            "        [-0.5008]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4348],\n",
            "        [-0.5225],\n",
            "        [-0.3798],\n",
            "        [-0.4442],\n",
            "        [-0.3673],\n",
            "        [-0.1675],\n",
            "        [ 0.1650],\n",
            "        [ 0.1505],\n",
            "        [-0.3579],\n",
            "        [-0.5528],\n",
            "        [-0.4671],\n",
            "        [-0.4465]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4911],\n",
            "        [-0.3477],\n",
            "        [-0.4099],\n",
            "        [-0.3776],\n",
            "        [-0.2420],\n",
            "        [ 0.0157],\n",
            "        [ 0.1359],\n",
            "        [-0.1278],\n",
            "        [-0.5326],\n",
            "        [-0.4360],\n",
            "        [-0.4287],\n",
            "        [-0.3985]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3211],\n",
            "        [-0.3632],\n",
            "        [-0.3591],\n",
            "        [-0.2594],\n",
            "        [-0.0930],\n",
            "        [-0.0045],\n",
            "        [-0.0396],\n",
            "        [-0.3408],\n",
            "        [-0.5086],\n",
            "        [-0.3381],\n",
            "        [-0.4177],\n",
            "        [-0.4006]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3481],\n",
            "        [-0.3371],\n",
            "        [-0.2510],\n",
            "        [-0.1170],\n",
            "        [-0.0719],\n",
            "        [-0.0801],\n",
            "        [-0.2476],\n",
            "        [-0.4973],\n",
            "        [-0.3069],\n",
            "        [-0.4036],\n",
            "        [-0.4072],\n",
            "        [-0.2856]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3214],\n",
            "        [-0.2241],\n",
            "        [-0.1047],\n",
            "        [-0.1015],\n",
            "        [-0.1448],\n",
            "        [-0.2516],\n",
            "        [-0.4483],\n",
            "        [-0.3249],\n",
            "        [-0.3677],\n",
            "        [-0.4110],\n",
            "        [-0.2732],\n",
            "        [-0.2399]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2139],\n",
            "        [-0.0809],\n",
            "        [-0.1026],\n",
            "        [-0.1830],\n",
            "        [-0.2885],\n",
            "        [-0.4309],\n",
            "        [-0.3332],\n",
            "        [-0.3429],\n",
            "        [-0.3935],\n",
            "        [-0.2437],\n",
            "        [-0.1990],\n",
            "        [-0.0999]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0802],\n",
            "        [-0.0970],\n",
            "        [-0.2035],\n",
            "        [-0.3125],\n",
            "        [-0.4332],\n",
            "        [-0.3384],\n",
            "        [-0.3270],\n",
            "        [-0.3584],\n",
            "        [-0.1926],\n",
            "        [-0.1468],\n",
            "        [-0.1002],\n",
            "        [ 0.0537]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1100],\n",
            "        [-0.2164],\n",
            "        [-0.3276],\n",
            "        [-0.4372],\n",
            "        [-0.3448],\n",
            "        [-0.3140],\n",
            "        [-0.3218],\n",
            "        [-0.1378],\n",
            "        [-0.1106],\n",
            "        [-0.1386],\n",
            "        [-0.0329],\n",
            "        [ 0.0790]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2275],\n",
            "        [-0.3334],\n",
            "        [-0.4455],\n",
            "        [-0.3616],\n",
            "        [-0.3279],\n",
            "        [-0.3086],\n",
            "        [-0.0892],\n",
            "        [-0.0506],\n",
            "        [-0.1412],\n",
            "        [-0.0761],\n",
            "        [ 0.0324],\n",
            "        [-0.0755]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3324],\n",
            "        [-0.4343],\n",
            "        [-0.3664],\n",
            "        [-0.3439],\n",
            "        [-0.3396],\n",
            "        [-0.1204],\n",
            "        [-0.0204],\n",
            "        [-0.0464],\n",
            "        [-0.0191],\n",
            "        [ 0.0615],\n",
            "        [-0.1101],\n",
            "        [-0.2469]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4236],\n",
            "        [-0.3433],\n",
            "        [-0.3304],\n",
            "        [-0.3562],\n",
            "        [-0.1854],\n",
            "        [-0.0907],\n",
            "        [ 0.0089],\n",
            "        [ 0.1196],\n",
            "        [ 0.1579],\n",
            "        [-0.1094],\n",
            "        [-0.3425],\n",
            "        [-0.3013]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3311],\n",
            "        [-0.2912],\n",
            "        [-0.3447],\n",
            "        [-0.2150],\n",
            "        [-0.1789],\n",
            "        [-0.0705],\n",
            "        [ 0.1806],\n",
            "        [ 0.3283],\n",
            "        [ 0.0053],\n",
            "        [-0.3996],\n",
            "        [-0.3834],\n",
            "        [-0.2604]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2847],\n",
            "        [-0.3199],\n",
            "        [-0.2165],\n",
            "        [-0.2074],\n",
            "        [-0.1393],\n",
            "        [ 0.1203],\n",
            "        [ 0.3858],\n",
            "        [ 0.1917],\n",
            "        [-0.3336],\n",
            "        [-0.4516],\n",
            "        [-0.2670],\n",
            "        [-0.2148]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3162],\n",
            "        [-0.2008],\n",
            "        [-0.2079],\n",
            "        [-0.1724],\n",
            "        [ 0.0490],\n",
            "        [ 0.3318],\n",
            "        [ 0.3045],\n",
            "        [-0.1343],\n",
            "        [-0.4899],\n",
            "        [-0.2887],\n",
            "        [-0.2138],\n",
            "        [-0.1909]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1966],\n",
            "        [-0.1848],\n",
            "        [-0.1819],\n",
            "        [ 0.0007],\n",
            "        [ 0.2352],\n",
            "        [ 0.2835],\n",
            "        [ 0.0762],\n",
            "        [-0.3642],\n",
            "        [-0.3889],\n",
            "        [-0.1729],\n",
            "        [-0.2169],\n",
            "        [-0.1819]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1889],\n",
            "        [-0.1797],\n",
            "        [-0.0225],\n",
            "        [ 0.1824],\n",
            "        [ 0.2365],\n",
            "        [ 0.1520],\n",
            "        [-0.2053],\n",
            "        [-0.4336],\n",
            "        [-0.1385],\n",
            "        [-0.2238],\n",
            "        [-0.1957],\n",
            "        [-0.0581]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1848],\n",
            "        [-0.0246],\n",
            "        [ 0.1555],\n",
            "        [ 0.1866],\n",
            "        [ 0.1377],\n",
            "        [-0.1035],\n",
            "        [-0.3914],\n",
            "        [-0.1393],\n",
            "        [-0.2093],\n",
            "        [-0.2091],\n",
            "        [-0.0617],\n",
            "        [-0.0253]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0297],\n",
            "        [ 0.1501],\n",
            "        [ 0.1513],\n",
            "        [ 0.0892],\n",
            "        [-0.0847],\n",
            "        [-0.3210],\n",
            "        [-0.1441],\n",
            "        [-0.1841],\n",
            "        [-0.2035],\n",
            "        [-0.0473],\n",
            "        [-0.0050],\n",
            "        [ 0.1205]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1335],\n",
            "        [ 0.1185],\n",
            "        [ 0.0465],\n",
            "        [-0.0926],\n",
            "        [-0.2811],\n",
            "        [-0.1319],\n",
            "        [-0.1563],\n",
            "        [-0.1827],\n",
            "        [-0.0175],\n",
            "        [ 0.0250],\n",
            "        [ 0.1266],\n",
            "        [ 0.3786]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0782],\n",
            "        [-0.0030],\n",
            "        [-0.1083],\n",
            "        [-0.2580],\n",
            "        [-0.1128],\n",
            "        [-0.1164],\n",
            "        [-0.1551],\n",
            "        [ 0.0017],\n",
            "        [ 0.0108],\n",
            "        [ 0.0505],\n",
            "        [ 0.2525],\n",
            "        [ 0.3590]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0388],\n",
            "        [-0.1467],\n",
            "        [-0.2710],\n",
            "        [-0.1232],\n",
            "        [-0.1013],\n",
            "        [-0.0989],\n",
            "        [ 0.0741],\n",
            "        [ 0.0440],\n",
            "        [-0.0111],\n",
            "        [ 0.1269],\n",
            "        [ 0.2175],\n",
            "        [ 0.1474]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1696],\n",
            "        [-0.2906],\n",
            "        [-0.1530],\n",
            "        [-0.1290],\n",
            "        [-0.0941],\n",
            "        [ 0.1246],\n",
            "        [ 0.1263],\n",
            "        [ 0.0280],\n",
            "        [ 0.1119],\n",
            "        [ 0.1793],\n",
            "        [ 0.0822],\n",
            "        [-0.0452]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2997],\n",
            "        [-0.1584],\n",
            "        [-0.1456],\n",
            "        [-0.1267],\n",
            "        [ 0.0838],\n",
            "        [ 0.1394],\n",
            "        [ 0.1346],\n",
            "        [ 0.2185],\n",
            "        [ 0.2298],\n",
            "        [ 0.0380],\n",
            "        [-0.1701],\n",
            "        [-0.1463]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1579],\n",
            "        [-0.1278],\n",
            "        [-0.1431],\n",
            "        [ 0.0280],\n",
            "        [ 0.0648],\n",
            "        [ 0.1409],\n",
            "        [ 0.3425],\n",
            "        [ 0.3873],\n",
            "        [ 0.1040],\n",
            "        [-0.2792],\n",
            "        [-0.2736],\n",
            "        [-0.0748]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1387],\n",
            "        [-0.1515],\n",
            "        [-0.0052],\n",
            "        [ 0.0198],\n",
            "        [ 0.1100],\n",
            "        [ 0.3732],\n",
            "        [ 0.5104],\n",
            "        [ 0.2482],\n",
            "        [-0.3152],\n",
            "        [-0.3879],\n",
            "        [-0.0988],\n",
            "        [-0.0574]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1644],\n",
            "        [-0.0196],\n",
            "        [-0.0103],\n",
            "        [ 0.0647],\n",
            "        [ 0.3310],\n",
            "        [ 0.5417],\n",
            "        [ 0.4172],\n",
            "        [-0.1930],\n",
            "        [-0.4926],\n",
            "        [-0.1273],\n",
            "        [-0.0771],\n",
            "        [-0.0374]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0294],\n",
            "        [-0.0205],\n",
            "        [ 0.0253],\n",
            "        [ 0.2623],\n",
            "        [ 0.4765],\n",
            "        [ 0.4904],\n",
            "        [ 0.0577],\n",
            "        [-0.4553],\n",
            "        [-0.2325],\n",
            "        [-0.0658],\n",
            "        [-0.0710],\n",
            "        [-0.0381]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0437],\n",
            "        [-0.0062],\n",
            "        [ 0.2096],\n",
            "        [ 0.4158],\n",
            "        [ 0.4946],\n",
            "        [ 0.2271],\n",
            "        [-0.3060],\n",
            "        [-0.3266],\n",
            "        [-0.0464],\n",
            "        [-0.0967],\n",
            "        [-0.0639],\n",
            "        [ 0.1122]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0278],\n",
            "        [ 0.1752],\n",
            "        [ 0.3565],\n",
            "        [ 0.4367],\n",
            "        [ 0.2725],\n",
            "        [-0.1369],\n",
            "        [-0.3225],\n",
            "        [-0.0469],\n",
            "        [-0.0955],\n",
            "        [-0.0774],\n",
            "        [ 0.1076],\n",
            "        [ 0.1705]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1552],\n",
            "        [ 0.3157],\n",
            "        [ 0.3708],\n",
            "        [ 0.2359],\n",
            "        [-0.0597],\n",
            "        [-0.2475],\n",
            "        [-0.0541],\n",
            "        [-0.0705],\n",
            "        [-0.0646],\n",
            "        [ 0.1343],\n",
            "        [ 0.2125],\n",
            "        [ 0.3920]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2757],\n",
            "        [ 0.3103],\n",
            "        [ 0.2086],\n",
            "        [-0.0151],\n",
            "        [-0.2133],\n",
            "        [-0.0525],\n",
            "        [-0.0551],\n",
            "        [-0.0679],\n",
            "        [ 0.1425],\n",
            "        [ 0.2167],\n",
            "        [ 0.3778],\n",
            "        [ 0.6995]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2489],\n",
            "        [ 0.1510],\n",
            "        [ 0.0136],\n",
            "        [-0.1576],\n",
            "        [-0.0429],\n",
            "        [-0.0212],\n",
            "        [-0.0791],\n",
            "        [ 0.1270],\n",
            "        [ 0.1574],\n",
            "        [ 0.2442],\n",
            "        [ 0.5091],\n",
            "        [ 0.6248]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0883],\n",
            "        [-0.0351],\n",
            "        [-0.1398],\n",
            "        [-0.0203],\n",
            "        [ 0.0204],\n",
            "        [-0.0256],\n",
            "        [ 0.1753],\n",
            "        [ 0.1386],\n",
            "        [ 0.1002],\n",
            "        [ 0.2630],\n",
            "        [ 0.3554],\n",
            "        [ 0.2718]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0760],\n",
            "        [-0.1767],\n",
            "        [-0.0493],\n",
            "        [ 0.0035],\n",
            "        [ 0.0050],\n",
            "        [ 0.2498],\n",
            "        [ 0.2179],\n",
            "        [ 0.1134],\n",
            "        [ 0.2125],\n",
            "        [ 0.2818],\n",
            "        [ 0.1801],\n",
            "        [-0.0123]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1959],\n",
            "        [-0.0710],\n",
            "        [-0.0262],\n",
            "        [-0.0236],\n",
            "        [ 0.2285],\n",
            "        [ 0.2491],\n",
            "        [ 0.2163],\n",
            "        [ 0.3232],\n",
            "        [ 0.3411],\n",
            "        [ 0.1444],\n",
            "        [-0.1341],\n",
            "        [-0.1627]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0763],\n",
            "        [-0.0292],\n",
            "        [-0.0511],\n",
            "        [ 0.1721],\n",
            "        [ 0.1977],\n",
            "        [ 0.2466],\n",
            "        [ 0.4432],\n",
            "        [ 0.4828],\n",
            "        [ 0.2164],\n",
            "        [-0.1977],\n",
            "        [-0.2418],\n",
            "        [ 0.0457]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0463],\n",
            "        [-0.0724],\n",
            "        [ 0.1302],\n",
            "        [ 0.1570],\n",
            "        [ 0.2406],\n",
            "        [ 0.4994],\n",
            "        [ 0.6071],\n",
            "        [ 0.3423],\n",
            "        [-0.2305],\n",
            "        [-0.3349],\n",
            "        [ 0.0300],\n",
            "        [ 0.1072]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0939],\n",
            "        [ 0.1006],\n",
            "        [ 0.1179],\n",
            "        [ 0.2057],\n",
            "        [ 0.4885],\n",
            "        [ 0.6707],\n",
            "        [ 0.5016],\n",
            "        [-0.1598],\n",
            "        [-0.4192],\n",
            "        [ 0.0050],\n",
            "        [ 0.0882],\n",
            "        [ 0.1020]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0858],\n",
            "        [ 0.0942],\n",
            "        [ 0.1579],\n",
            "        [ 0.4217],\n",
            "        [ 0.6296],\n",
            "        [ 0.6042],\n",
            "        [ 0.0661],\n",
            "        [-0.3884],\n",
            "        [-0.0747],\n",
            "        [ 0.0988],\n",
            "        [ 0.0898],\n",
            "        [ 0.1227]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0584],\n",
            "        [ 0.1110],\n",
            "        [ 0.3638],\n",
            "        [ 0.5854],\n",
            "        [ 0.6533],\n",
            "        [ 0.2414],\n",
            "        [-0.3261],\n",
            "        [-0.1589],\n",
            "        [ 0.0920],\n",
            "        [ 0.0581],\n",
            "        [ 0.0869],\n",
            "        [ 0.2151]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0784],\n",
            "        [ 0.3114],\n",
            "        [ 0.5136],\n",
            "        [ 0.6104],\n",
            "        [ 0.3367],\n",
            "        [-0.1598],\n",
            "        [-0.1818],\n",
            "        [ 0.0889],\n",
            "        [ 0.0559],\n",
            "        [ 0.0748],\n",
            "        [ 0.2043],\n",
            "        [ 0.2391]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2817],\n",
            "        [ 0.4546],\n",
            "        [ 0.5416],\n",
            "        [ 0.3375],\n",
            "        [-0.0425],\n",
            "        [-0.1318],\n",
            "        [ 0.0867],\n",
            "        [ 0.0740],\n",
            "        [ 0.0800],\n",
            "        [ 0.2105],\n",
            "        [ 0.2555],\n",
            "        [ 0.4286]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4013],\n",
            "        [ 0.4773],\n",
            "        [ 0.3508],\n",
            "        [ 0.0436],\n",
            "        [-0.1660],\n",
            "        [ 0.0532],\n",
            "        [ 0.0464],\n",
            "        [ 0.0353],\n",
            "        [ 0.1810],\n",
            "        [ 0.2285],\n",
            "        [ 0.4081],\n",
            "        [ 0.7888]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4029],\n",
            "        [ 0.2988],\n",
            "        [ 0.1358],\n",
            "        [-0.0996],\n",
            "        [ 0.0075],\n",
            "        [ 0.0420],\n",
            "        [-0.0303],\n",
            "        [ 0.1286],\n",
            "        [ 0.1480],\n",
            "        [ 0.2813],\n",
            "        [ 0.6107],\n",
            "        [ 0.8529]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2173],\n",
            "        [ 0.0908],\n",
            "        [-0.0224],\n",
            "        [ 0.0679],\n",
            "        [ 0.0908],\n",
            "        [-0.0082],\n",
            "        [ 0.1158],\n",
            "        [ 0.0570],\n",
            "        [ 0.0837],\n",
            "        [ 0.3043],\n",
            "        [ 0.4749],\n",
            "        [ 0.5041]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0362],\n",
            "        [-0.0706],\n",
            "        [ 0.0535],\n",
            "        [ 0.0978],\n",
            "        [ 0.0506],\n",
            "        [ 0.2023],\n",
            "        [ 0.1022],\n",
            "        [ 0.0484],\n",
            "        [ 0.2218],\n",
            "        [ 0.3441],\n",
            "        [ 0.3333],\n",
            "        [ 0.1223]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1028],\n",
            "        [ 0.0126],\n",
            "        [ 0.0533],\n",
            "        [ 0.0351],\n",
            "        [ 0.2273],\n",
            "        [ 0.1714],\n",
            "        [ 0.1331],\n",
            "        [ 0.2924],\n",
            "        [ 0.3677],\n",
            "        [ 0.2606],\n",
            "        [-0.0464],\n",
            "        [-0.1261]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0055],\n",
            "        [ 0.0292],\n",
            "        [-0.0066],\n",
            "        [ 0.1762],\n",
            "        [ 0.1592],\n",
            "        [ 0.2014],\n",
            "        [ 0.4027],\n",
            "        [ 0.4839],\n",
            "        [ 0.3049],\n",
            "        [-0.1599],\n",
            "        [-0.2647],\n",
            "        [-0.0019]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0047],\n",
            "        [-0.0414],\n",
            "        [ 0.1267],\n",
            "        [ 0.1259],\n",
            "        [ 0.2203],\n",
            "        [ 0.4768],\n",
            "        [ 0.6072],\n",
            "        [ 0.4061],\n",
            "        [-0.2452],\n",
            "        [-0.3912],\n",
            "        [-0.0079],\n",
            "        [ 0.0230]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0668],\n",
            "        [ 0.0876],\n",
            "        [ 0.0806],\n",
            "        [ 0.1884],\n",
            "        [ 0.4764],\n",
            "        [ 0.6830],\n",
            "        [ 0.5628],\n",
            "        [-0.2105],\n",
            "        [-0.4911],\n",
            "        [-0.0075],\n",
            "        [ 0.0053],\n",
            "        [ 0.0339]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0695],\n",
            "        [ 0.0521],\n",
            "        [ 0.1367],\n",
            "        [ 0.4075],\n",
            "        [ 0.6436],\n",
            "        [ 0.6654],\n",
            "        [-0.0019],\n",
            "        [-0.4804],\n",
            "        [-0.0729],\n",
            "        [ 0.0242],\n",
            "        [ 0.0280],\n",
            "        [ 0.0594]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0265],\n",
            "        [ 0.0936],\n",
            "        [ 0.3451],\n",
            "        [ 0.5848],\n",
            "        [ 0.6941],\n",
            "        [ 0.1820],\n",
            "        [-0.3868],\n",
            "        [-0.1515],\n",
            "        [ 0.0434],\n",
            "        [ 0.0236],\n",
            "        [ 0.0524],\n",
            "        [ 0.2266]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0729],\n",
            "        [ 0.3005],\n",
            "        [ 0.5123],\n",
            "        [ 0.6325],\n",
            "        [ 0.2717],\n",
            "        [-0.1907],\n",
            "        [-0.1669],\n",
            "        [ 0.0561],\n",
            "        [ 0.0478],\n",
            "        [ 0.0699],\n",
            "        [ 0.2468],\n",
            "        [ 0.3102]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2830],\n",
            "        [ 0.4618],\n",
            "        [ 0.5648],\n",
            "        [ 0.2791],\n",
            "        [-0.0560],\n",
            "        [-0.1017],\n",
            "        [ 0.0709],\n",
            "        [ 0.0915],\n",
            "        [ 0.1035],\n",
            "        [ 0.2850],\n",
            "        [ 0.3636],\n",
            "        [ 0.5889]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4312],\n",
            "        [ 0.5134],\n",
            "        [ 0.2938],\n",
            "        [ 0.0186],\n",
            "        [-0.1243],\n",
            "        [ 0.0596],\n",
            "        [ 0.0882],\n",
            "        [ 0.0929],\n",
            "        [ 0.2876],\n",
            "        [ 0.3682],\n",
            "        [ 0.5899],\n",
            "        [ 0.8541]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4676],\n",
            "        [ 0.2623],\n",
            "        [ 0.1207],\n",
            "        [-0.1022],\n",
            "        [ 0.0103],\n",
            "        [ 0.0846],\n",
            "        [ 0.0416],\n",
            "        [ 0.2591],\n",
            "        [ 0.3094],\n",
            "        [ 0.4779],\n",
            "        [ 0.6938],\n",
            "        [ 0.8541]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2013],\n",
            "        [ 0.1039],\n",
            "        [-0.0165],\n",
            "        [ 0.0637],\n",
            "        [ 0.1489],\n",
            "        [ 0.0670],\n",
            "        [ 0.2463],\n",
            "        [ 0.1811],\n",
            "        [ 0.1779],\n",
            "        [ 0.2806],\n",
            "        [ 0.4522],\n",
            "        [ 0.5118]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0705],\n",
            "        [-0.0537],\n",
            "        [ 0.0566],\n",
            "        [ 0.1570],\n",
            "        [ 0.1248],\n",
            "        [ 0.3434],\n",
            "        [ 0.2491],\n",
            "        [ 0.1596],\n",
            "        [ 0.2025],\n",
            "        [ 0.3735],\n",
            "        [ 0.4280],\n",
            "        [ 0.3477]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0812],\n",
            "        [ 0.0214],\n",
            "        [ 0.1196],\n",
            "        [ 0.1189],\n",
            "        [ 0.3832],\n",
            "        [ 0.3492],\n",
            "        [ 0.2816],\n",
            "        [ 0.2739],\n",
            "        [ 0.3847],\n",
            "        [ 0.3621],\n",
            "        [ 0.2067],\n",
            "        [ 0.1687]], grad_fn=<AddmmBackward>)\n",
            "tensor([[0.0068],\n",
            "        [0.0994],\n",
            "        [0.0843],\n",
            "        [0.3354],\n",
            "        [0.3523],\n",
            "        [0.3959],\n",
            "        [0.4422],\n",
            "        [0.5024],\n",
            "        [0.3701],\n",
            "        [0.1158],\n",
            "        [0.0644],\n",
            "        [0.2760]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7385],\n",
            "        [-0.7498],\n",
            "        [-0.7204],\n",
            "        [-0.7768],\n",
            "        [-0.8101],\n",
            "        [-0.7503],\n",
            "        [-0.6076],\n",
            "        [-0.4323],\n",
            "        [-0.4435],\n",
            "        [-0.7303],\n",
            "        [-0.7632],\n",
            "        [-0.7876]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7210],\n",
            "        [-0.7025],\n",
            "        [-0.7396],\n",
            "        [-0.7963],\n",
            "        [-0.7726],\n",
            "        [-0.7222],\n",
            "        [-0.6022],\n",
            "        [-0.4651],\n",
            "        [-0.5315],\n",
            "        [-0.7746],\n",
            "        [-0.6810],\n",
            "        [-0.8382]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6772],\n",
            "        [-0.7184],\n",
            "        [-0.7713],\n",
            "        [-0.7557],\n",
            "        [-0.7502],\n",
            "        [-0.7156],\n",
            "        [-0.6288],\n",
            "        [-0.5273],\n",
            "        [-0.6319],\n",
            "        [-0.6611],\n",
            "        [-0.7709],\n",
            "        [-0.8003]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6907],\n",
            "        [-0.7539],\n",
            "        [-0.7264],\n",
            "        [-0.7331],\n",
            "        [-0.7449],\n",
            "        [-0.7419],\n",
            "        [-0.6756],\n",
            "        [-0.6122],\n",
            "        [-0.5811],\n",
            "        [-0.7129],\n",
            "        [-0.7903],\n",
            "        [-0.7536]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7224],\n",
            "        [-0.7107],\n",
            "        [-0.6945],\n",
            "        [-0.7389],\n",
            "        [-0.7784],\n",
            "        [-0.8024],\n",
            "        [-0.7533],\n",
            "        [-0.5771],\n",
            "        [-0.6326],\n",
            "        [-0.7016],\n",
            "        [-0.7442],\n",
            "        [-0.7831]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6805],\n",
            "        [-0.6723],\n",
            "        [-0.7063],\n",
            "        [-0.7790],\n",
            "        [-0.8479],\n",
            "        [-0.8853],\n",
            "        [-0.7459],\n",
            "        [-0.6512],\n",
            "        [-0.5287],\n",
            "        [-0.5883],\n",
            "        [-0.7517],\n",
            "        [-0.8303]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6403],\n",
            "        [-0.6799],\n",
            "        [-0.7565],\n",
            "        [-0.8427],\n",
            "        [-0.9226],\n",
            "        [-0.8732],\n",
            "        [-0.8201],\n",
            "        [-0.5823],\n",
            "        [-0.3832],\n",
            "        [-0.5712],\n",
            "        [-0.7880],\n",
            "        [-0.7182]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6443],\n",
            "        [-0.7331],\n",
            "        [-0.8257],\n",
            "        [-0.9087],\n",
            "        [-0.9065],\n",
            "        [-0.9287],\n",
            "        [-0.7699],\n",
            "        [-0.4857],\n",
            "        [-0.3355],\n",
            "        [-0.6566],\n",
            "        [-0.6031],\n",
            "        [-0.6853]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6903],\n",
            "        [-0.8073],\n",
            "        [-0.8881],\n",
            "        [-0.8832],\n",
            "        [-0.9525],\n",
            "        [-0.8879],\n",
            "        [-0.7051],\n",
            "        [-0.4352],\n",
            "        [-0.3590],\n",
            "        [-0.5735],\n",
            "        [-0.5148],\n",
            "        [-0.7580]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7537],\n",
            "        [-0.8749],\n",
            "        [-0.8432],\n",
            "        [-0.9237],\n",
            "        [-0.9144],\n",
            "        [-0.8508],\n",
            "        [-0.6841],\n",
            "        [-0.4114],\n",
            "        [-0.2667],\n",
            "        [-0.4908],\n",
            "        [-0.6464],\n",
            "        [-0.8379]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8105],\n",
            "        [-0.8308],\n",
            "        [-0.8674],\n",
            "        [-0.8927],\n",
            "        [-0.8826],\n",
            "        [-0.8609],\n",
            "        [-0.6801],\n",
            "        [-0.2722],\n",
            "        [-0.2261],\n",
            "        [-0.5798],\n",
            "        [-0.7553],\n",
            "        [-0.9169]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7661],\n",
            "        [-0.8492],\n",
            "        [-0.8337],\n",
            "        [-0.8552],\n",
            "        [-0.9009],\n",
            "        [-0.8807],\n",
            "        [-0.5827],\n",
            "        [-0.2049],\n",
            "        [-0.2655],\n",
            "        [-0.7040],\n",
            "        [-0.7934],\n",
            "        [-0.9507]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7789],\n",
            "        [-0.8114],\n",
            "        [-0.7857],\n",
            "        [-0.8763],\n",
            "        [-0.9195],\n",
            "        [-0.8005],\n",
            "        [-0.5282],\n",
            "        [-0.2052],\n",
            "        [-0.3364],\n",
            "        [-0.8086],\n",
            "        [-0.7664],\n",
            "        [-0.8669]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7411],\n",
            "        [-0.7539],\n",
            "        [-0.8112],\n",
            "        [-0.8970],\n",
            "        [-0.8489],\n",
            "        [-0.7555],\n",
            "        [-0.5302],\n",
            "        [-0.2389],\n",
            "        [-0.4704],\n",
            "        [-0.8045],\n",
            "        [-0.6546],\n",
            "        [-0.8694]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6873],\n",
            "        [-0.7750],\n",
            "        [-0.8456],\n",
            "        [-0.8152],\n",
            "        [-0.7982],\n",
            "        [-0.7331],\n",
            "        [-0.5378],\n",
            "        [-0.3562],\n",
            "        [-0.6224],\n",
            "        [-0.5512],\n",
            "        [-0.7814],\n",
            "        [-0.8357]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7058],\n",
            "        [-0.8094],\n",
            "        [-0.7514],\n",
            "        [-0.7555],\n",
            "        [-0.7624],\n",
            "        [-0.7203],\n",
            "        [-0.5967],\n",
            "        [-0.5159],\n",
            "        [-0.5382],\n",
            "        [-0.6196],\n",
            "        [-0.8406],\n",
            "        [-0.7099]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7390],\n",
            "        [-0.7140],\n",
            "        [-0.6780],\n",
            "        [-0.7365],\n",
            "        [-0.7630],\n",
            "        [-0.7873],\n",
            "        [-0.7024],\n",
            "        [-0.4663],\n",
            "        [-0.5724],\n",
            "        [-0.7361],\n",
            "        [-0.7190],\n",
            "        [-0.7573]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6509],\n",
            "        [-0.6240],\n",
            "        [-0.6688],\n",
            "        [-0.7441],\n",
            "        [-0.8375],\n",
            "        [-0.8745],\n",
            "        [-0.6663],\n",
            "        [-0.5496],\n",
            "        [-0.5205],\n",
            "        [-0.5388],\n",
            "        [-0.7283],\n",
            "        [-0.7110]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5732],\n",
            "        [-0.6150],\n",
            "        [-0.7014],\n",
            "        [-0.8181],\n",
            "        [-0.9090],\n",
            "        [-0.8117],\n",
            "        [-0.7273],\n",
            "        [-0.5049],\n",
            "        [-0.2592],\n",
            "        [-0.5600],\n",
            "        [-0.6590],\n",
            "        [-0.6734]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5699],\n",
            "        [-0.6550],\n",
            "        [-0.7878],\n",
            "        [-0.8822],\n",
            "        [-0.8390],\n",
            "        [-0.8340],\n",
            "        [-0.6724],\n",
            "        [-0.3048],\n",
            "        [-0.2984],\n",
            "        [-0.5743],\n",
            "        [-0.5444],\n",
            "        [-0.6223]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6090],\n",
            "        [-0.7467],\n",
            "        [-0.8527],\n",
            "        [-0.8014],\n",
            "        [-0.8500],\n",
            "        [-0.7802],\n",
            "        [-0.5121],\n",
            "        [-0.3078],\n",
            "        [-0.2959],\n",
            "        [-0.5445],\n",
            "        [-0.5022],\n",
            "        [-0.6429]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6938],\n",
            "        [-0.8180],\n",
            "        [-0.7522],\n",
            "        [-0.8080],\n",
            "        [-0.7998],\n",
            "        [-0.6577],\n",
            "        [-0.5149],\n",
            "        [-0.2127],\n",
            "        [-0.3818],\n",
            "        [-0.4415],\n",
            "        [-0.5792],\n",
            "        [-0.6855]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7577],\n",
            "        [-0.7180],\n",
            "        [-0.7399],\n",
            "        [-0.7729],\n",
            "        [-0.6949],\n",
            "        [-0.6887],\n",
            "        [-0.4158],\n",
            "        [-0.2398],\n",
            "        [-0.3317],\n",
            "        [-0.4820],\n",
            "        [-0.6612],\n",
            "        [-0.7434]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6662],\n",
            "        [-0.6957],\n",
            "        [-0.7155],\n",
            "        [-0.6681],\n",
            "        [-0.7360],\n",
            "        [-0.6149],\n",
            "        [-0.4342],\n",
            "        [-0.1686],\n",
            "        [-0.3537],\n",
            "        [-0.6043],\n",
            "        [-0.7137],\n",
            "        [-0.7644]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6473],\n",
            "        [-0.6745],\n",
            "        [-0.6115],\n",
            "        [-0.7137],\n",
            "        [-0.6647],\n",
            "        [-0.6053],\n",
            "        [-0.3414],\n",
            "        [-0.2136],\n",
            "        [-0.4560],\n",
            "        [-0.6853],\n",
            "        [-0.7045],\n",
            "        [-0.6889]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6289],\n",
            "        [-0.5672],\n",
            "        [-0.6654],\n",
            "        [-0.6542],\n",
            "        [-0.6565],\n",
            "        [-0.5160],\n",
            "        [-0.3655],\n",
            "        [-0.2863],\n",
            "        [-0.5691],\n",
            "        [-0.6806],\n",
            "        [-0.6184],\n",
            "        [-0.6798]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5294],\n",
            "        [-0.6174],\n",
            "        [-0.6215],\n",
            "        [-0.6384],\n",
            "        [-0.5753],\n",
            "        [-0.5201],\n",
            "        [-0.4078],\n",
            "        [-0.4116],\n",
            "        [-0.6397],\n",
            "        [-0.5266],\n",
            "        [-0.6613],\n",
            "        [-0.6279]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5811],\n",
            "        [-0.5853],\n",
            "        [-0.6033],\n",
            "        [-0.5636],\n",
            "        [-0.5653],\n",
            "        [-0.5307],\n",
            "        [-0.4867],\n",
            "        [-0.5352],\n",
            "        [-0.5219],\n",
            "        [-0.5806],\n",
            "        [-0.6481],\n",
            "        [-0.5829]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5493],\n",
            "        [-0.5617],\n",
            "        [-0.5247],\n",
            "        [-0.5575],\n",
            "        [-0.5873],\n",
            "        [-0.6103],\n",
            "        [-0.5948],\n",
            "        [-0.4773],\n",
            "        [-0.5322],\n",
            "        [-0.5976],\n",
            "        [-0.5835],\n",
            "        [-0.6210]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5284],\n",
            "        [-0.4834],\n",
            "        [-0.5231],\n",
            "        [-0.5889],\n",
            "        [-0.6613],\n",
            "        [-0.6944],\n",
            "        [-0.5588],\n",
            "        [-0.5129],\n",
            "        [-0.4846],\n",
            "        [-0.4936],\n",
            "        [-0.5939],\n",
            "        [-0.5929]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4536],\n",
            "        [-0.4780],\n",
            "        [-0.5674],\n",
            "        [-0.6596],\n",
            "        [-0.7323],\n",
            "        [-0.6540],\n",
            "        [-0.6020],\n",
            "        [-0.4584],\n",
            "        [-0.3418],\n",
            "        [-0.4746],\n",
            "        [-0.5712],\n",
            "        [-0.4575]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4528],\n",
            "        [-0.5322],\n",
            "        [-0.6477],\n",
            "        [-0.7238],\n",
            "        [-0.6848],\n",
            "        [-0.6728],\n",
            "        [-0.5441],\n",
            "        [-0.3405],\n",
            "        [-0.3336],\n",
            "        [-0.4904],\n",
            "        [-0.3937],\n",
            "        [-0.4632]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5043],\n",
            "        [-0.6157],\n",
            "        [-0.7093],\n",
            "        [-0.6675],\n",
            "        [-0.6951],\n",
            "        [-0.6204],\n",
            "        [-0.4538],\n",
            "        [-0.3226],\n",
            "        [-0.3331],\n",
            "        [-0.3341],\n",
            "        [-0.4003],\n",
            "        [-0.4629]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5810],\n",
            "        [-0.6798],\n",
            "        [-0.6394],\n",
            "        [-0.6721],\n",
            "        [-0.6486],\n",
            "        [-0.5587],\n",
            "        [-0.4502],\n",
            "        [-0.2780],\n",
            "        [-0.2016],\n",
            "        [-0.3250],\n",
            "        [-0.4418],\n",
            "        [-0.5936]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6367],\n",
            "        [-0.6079],\n",
            "        [-0.6272],\n",
            "        [-0.6319],\n",
            "        [-0.5964],\n",
            "        [-0.5783],\n",
            "        [-0.4108],\n",
            "        [-0.1366],\n",
            "        [-0.1943],\n",
            "        [-0.3534],\n",
            "        [-0.5942],\n",
            "        [-0.6285]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5674],\n",
            "        [-0.5878],\n",
            "        [-0.5904],\n",
            "        [-0.5805],\n",
            "        [-0.6244],\n",
            "        [-0.5546],\n",
            "        [-0.2953],\n",
            "        [-0.1254],\n",
            "        [-0.1445],\n",
            "        [-0.5288],\n",
            "        [-0.6326],\n",
            "        [-0.6227]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5502],\n",
            "        [-0.5546],\n",
            "        [-0.5428],\n",
            "        [-0.6137],\n",
            "        [-0.6001],\n",
            "        [-0.4373],\n",
            "        [-0.2673],\n",
            "        [-0.0542],\n",
            "        [-0.3223],\n",
            "        [-0.6137],\n",
            "        [-0.5709],\n",
            "        [-0.5550]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5193],\n",
            "        [-0.5060],\n",
            "        [-0.5841],\n",
            "        [-0.5947],\n",
            "        [-0.4911],\n",
            "        [-0.4029],\n",
            "        [-0.1859],\n",
            "        [-0.1995],\n",
            "        [-0.4403],\n",
            "        [-0.5808],\n",
            "        [-0.4809],\n",
            "        [-0.5827]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4742],\n",
            "        [-0.5489],\n",
            "        [-0.5743],\n",
            "        [-0.4821],\n",
            "        [-0.4548],\n",
            "        [-0.3172],\n",
            "        [-0.2887],\n",
            "        [-0.2985],\n",
            "        [-0.5491],\n",
            "        [-0.4176],\n",
            "        [-0.5672],\n",
            "        [-0.5691]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5156],\n",
            "        [-0.5430],\n",
            "        [-0.4500],\n",
            "        [-0.4451],\n",
            "        [-0.3674],\n",
            "        [-0.3937],\n",
            "        [-0.3410],\n",
            "        [-0.4768],\n",
            "        [-0.4161],\n",
            "        [-0.5095],\n",
            "        [-0.5790],\n",
            "        [-0.4274]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5078],\n",
            "        [-0.4117],\n",
            "        [-0.4041],\n",
            "        [-0.3683],\n",
            "        [-0.4486],\n",
            "        [-0.4419],\n",
            "        [-0.5019],\n",
            "        [-0.4072],\n",
            "        [-0.4718],\n",
            "        [-0.5506],\n",
            "        [-0.4088],\n",
            "        [-0.4110]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3843],\n",
            "        [-0.3594],\n",
            "        [-0.3419],\n",
            "        [-0.4584],\n",
            "        [-0.5006],\n",
            "        [-0.5716],\n",
            "        [-0.4564],\n",
            "        [-0.4681],\n",
            "        [-0.4798],\n",
            "        [-0.3292],\n",
            "        [-0.3459],\n",
            "        [-0.3450]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3422],\n",
            "        [-0.3130],\n",
            "        [-0.4521],\n",
            "        [-0.5160],\n",
            "        [-0.6039],\n",
            "        [-0.5126],\n",
            "        [-0.5046],\n",
            "        [-0.4502],\n",
            "        [-0.2388],\n",
            "        [-0.2498],\n",
            "        [-0.3316],\n",
            "        [-0.3501]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2998],\n",
            "        [-0.4271],\n",
            "        [-0.5197],\n",
            "        [-0.6069],\n",
            "        [-0.5446],\n",
            "        [-0.5486],\n",
            "        [-0.4811],\n",
            "        [-0.2199],\n",
            "        [-0.1611],\n",
            "        [-0.2670],\n",
            "        [-0.3509],\n",
            "        [-0.2978]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4151],\n",
            "        [-0.5023],\n",
            "        [-0.6037],\n",
            "        [-0.5450],\n",
            "        [-0.5704],\n",
            "        [-0.5224],\n",
            "        [-0.2720],\n",
            "        [-0.1456],\n",
            "        [-0.1705],\n",
            "        [-0.2968],\n",
            "        [-0.2660],\n",
            "        [-0.3288]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4785],\n",
            "        [-0.5768],\n",
            "        [-0.5298],\n",
            "        [-0.5599],\n",
            "        [-0.5537],\n",
            "        [-0.3634],\n",
            "        [-0.2402],\n",
            "        [-0.1084],\n",
            "        [-0.1537],\n",
            "        [-0.2059],\n",
            "        [-0.2926],\n",
            "        [-0.5011]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5457],\n",
            "        [-0.4995],\n",
            "        [-0.5295],\n",
            "        [-0.5480],\n",
            "        [-0.4102],\n",
            "        [-0.3538],\n",
            "        [-0.1976],\n",
            "        [-0.0552],\n",
            "        [-0.0948],\n",
            "        [-0.2180],\n",
            "        [-0.4932],\n",
            "        [-0.6071]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4694],\n",
            "        [-0.4888],\n",
            "        [-0.5222],\n",
            "        [-0.4046],\n",
            "        [-0.4111],\n",
            "        [-0.3263],\n",
            "        [-0.1407],\n",
            "        [ 0.0093],\n",
            "        [-0.0954],\n",
            "        [-0.4414],\n",
            "        [-0.6057],\n",
            "        [-0.6148]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4628],\n",
            "        [-0.4888],\n",
            "        [-0.3773],\n",
            "        [-0.4085],\n",
            "        [-0.3813],\n",
            "        [-0.2542],\n",
            "        [-0.0541],\n",
            "        [ 0.0042],\n",
            "        [-0.3342],\n",
            "        [-0.5739],\n",
            "        [-0.5997],\n",
            "        [-0.5195]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4636],\n",
            "        [-0.3429],\n",
            "        [-0.3787],\n",
            "        [-0.3918],\n",
            "        [-0.3177],\n",
            "        [-0.1710],\n",
            "        [-0.0390],\n",
            "        [-0.2059],\n",
            "        [-0.4841],\n",
            "        [-0.5866],\n",
            "        [-0.4923],\n",
            "        [-0.5365]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3240],\n",
            "        [-0.3386],\n",
            "        [-0.3815],\n",
            "        [-0.3345],\n",
            "        [-0.2476],\n",
            "        [-0.1487],\n",
            "        [-0.2032],\n",
            "        [-0.3490],\n",
            "        [-0.5753],\n",
            "        [-0.4368],\n",
            "        [-0.5352],\n",
            "        [-0.5727]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3275],\n",
            "        [-0.3600],\n",
            "        [-0.3322],\n",
            "        [-0.2645],\n",
            "        [-0.2032],\n",
            "        [-0.2501],\n",
            "        [-0.3154],\n",
            "        [-0.5307],\n",
            "        [-0.4192],\n",
            "        [-0.5032],\n",
            "        [-0.5827],\n",
            "        [-0.4185]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3489],\n",
            "        [-0.3114],\n",
            "        [-0.2584],\n",
            "        [-0.2234],\n",
            "        [-0.2980],\n",
            "        [-0.3476],\n",
            "        [-0.5088],\n",
            "        [-0.4215],\n",
            "        [-0.4714],\n",
            "        [-0.5843],\n",
            "        [-0.4063],\n",
            "        [-0.4450]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2997],\n",
            "        [-0.2326],\n",
            "        [-0.2173],\n",
            "        [-0.3210],\n",
            "        [-0.3920],\n",
            "        [-0.5279],\n",
            "        [-0.4389],\n",
            "        [-0.4685],\n",
            "        [-0.5606],\n",
            "        [-0.3757],\n",
            "        [-0.4087],\n",
            "        [-0.2934]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2262],\n",
            "        [-0.1982],\n",
            "        [-0.3272],\n",
            "        [-0.4157],\n",
            "        [-0.5504],\n",
            "        [-0.4690],\n",
            "        [-0.4853],\n",
            "        [-0.5364],\n",
            "        [-0.3243],\n",
            "        [-0.3461],\n",
            "        [-0.2509],\n",
            "        [-0.1398]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1984],\n",
            "        [-0.3184],\n",
            "        [-0.4292],\n",
            "        [-0.5601],\n",
            "        [-0.4940],\n",
            "        [-0.5081],\n",
            "        [-0.5335],\n",
            "        [-0.2892],\n",
            "        [-0.2817],\n",
            "        [-0.2085],\n",
            "        [-0.1567],\n",
            "        [-0.0999]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3214],\n",
            "        [-0.4245],\n",
            "        [-0.5657],\n",
            "        [-0.5052],\n",
            "        [-0.5285],\n",
            "        [-0.5488],\n",
            "        [-0.2938],\n",
            "        [-0.2445],\n",
            "        [-0.1528],\n",
            "        [-0.1365],\n",
            "        [-0.1097],\n",
            "        [-0.2946]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4137],\n",
            "        [-0.5463],\n",
            "        [-0.5025],\n",
            "        [-0.5279],\n",
            "        [-0.5751],\n",
            "        [-0.3575],\n",
            "        [-0.2956],\n",
            "        [-0.1020],\n",
            "        [-0.0268],\n",
            "        [-0.0295],\n",
            "        [-0.2844],\n",
            "        [-0.5463]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5227],\n",
            "        [-0.4746],\n",
            "        [-0.5032],\n",
            "        [-0.5731],\n",
            "        [-0.4026],\n",
            "        [-0.3896],\n",
            "        [-0.1775],\n",
            "        [ 0.0430],\n",
            "        [ 0.1032],\n",
            "        [-0.1936],\n",
            "        [-0.5416],\n",
            "        [-0.6008]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4478],\n",
            "        [-0.4574],\n",
            "        [-0.5506],\n",
            "        [-0.4003],\n",
            "        [-0.4456],\n",
            "        [-0.3066],\n",
            "        [-0.0590],\n",
            "        [ 0.2083],\n",
            "        [-0.0132],\n",
            "        [-0.4756],\n",
            "        [-0.5714],\n",
            "        [-0.4961]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4362],\n",
            "        [-0.5132],\n",
            "        [-0.3782],\n",
            "        [-0.4422],\n",
            "        [-0.3643],\n",
            "        [-0.1808],\n",
            "        [ 0.1288],\n",
            "        [ 0.1327],\n",
            "        [-0.3142],\n",
            "        [-0.5578],\n",
            "        [-0.4541],\n",
            "        [-0.4459]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4911],\n",
            "        [-0.3420],\n",
            "        [-0.4116],\n",
            "        [-0.3746],\n",
            "        [-0.2475],\n",
            "        [-0.0062],\n",
            "        [ 0.1062],\n",
            "        [-0.1045],\n",
            "        [-0.4985],\n",
            "        [-0.4481],\n",
            "        [-0.4091],\n",
            "        [-0.4068]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3252],\n",
            "        [-0.3602],\n",
            "        [-0.3602],\n",
            "        [-0.2621],\n",
            "        [-0.1039],\n",
            "        [-0.0231],\n",
            "        [-0.0473],\n",
            "        [-0.3093],\n",
            "        [-0.5051],\n",
            "        [-0.3181],\n",
            "        [-0.4192],\n",
            "        [-0.4045]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3515],\n",
            "        [-0.3344],\n",
            "        [-0.2553],\n",
            "        [-0.1255],\n",
            "        [-0.0860],\n",
            "        [-0.0919],\n",
            "        [-0.2334],\n",
            "        [-0.4746],\n",
            "        [-0.2992],\n",
            "        [-0.3942],\n",
            "        [-0.4137],\n",
            "        [-0.2891]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3254],\n",
            "        [-0.2245],\n",
            "        [-0.1141],\n",
            "        [-0.1126],\n",
            "        [-0.1534],\n",
            "        [-0.2479],\n",
            "        [-0.4291],\n",
            "        [-0.3164],\n",
            "        [-0.3547],\n",
            "        [-0.4130],\n",
            "        [-0.2754],\n",
            "        [-0.2517]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2203],\n",
            "        [-0.0864],\n",
            "        [-0.1136],\n",
            "        [-0.1891],\n",
            "        [-0.2875],\n",
            "        [-0.4202],\n",
            "        [-0.3243],\n",
            "        [-0.3328],\n",
            "        [-0.3881],\n",
            "        [-0.2434],\n",
            "        [-0.2123],\n",
            "        [-0.1311]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0896],\n",
            "        [-0.1042],\n",
            "        [-0.2094],\n",
            "        [-0.3124],\n",
            "        [-0.4278],\n",
            "        [-0.3331],\n",
            "        [-0.3212],\n",
            "        [-0.3501],\n",
            "        [-0.1903],\n",
            "        [-0.1569],\n",
            "        [-0.1160],\n",
            "        [ 0.0414]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1183],\n",
            "        [-0.2196],\n",
            "        [-0.3284],\n",
            "        [-0.4339],\n",
            "        [-0.3431],\n",
            "        [-0.3138],\n",
            "        [-0.3171],\n",
            "        [-0.1361],\n",
            "        [-0.1114],\n",
            "        [-0.1304],\n",
            "        [-0.0230],\n",
            "        [ 0.0823]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2327],\n",
            "        [-0.3316],\n",
            "        [-0.4434],\n",
            "        [-0.3597],\n",
            "        [-0.3301],\n",
            "        [-0.3100],\n",
            "        [-0.0978],\n",
            "        [-0.0513],\n",
            "        [-0.1099],\n",
            "        [-0.0441],\n",
            "        [ 0.0485],\n",
            "        [-0.1056]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3345],\n",
            "        [-0.4286],\n",
            "        [-0.3658],\n",
            "        [-0.3436],\n",
            "        [-0.3401],\n",
            "        [-0.1329],\n",
            "        [-0.0361],\n",
            "        [-0.0216],\n",
            "        [ 0.0284],\n",
            "        [ 0.0952],\n",
            "        [-0.1248],\n",
            "        [-0.3306]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4223],\n",
            "        [-0.3373],\n",
            "        [-0.3313],\n",
            "        [-0.3531],\n",
            "        [-0.1901],\n",
            "        [-0.1058],\n",
            "        [ 0.0032],\n",
            "        [ 0.1468],\n",
            "        [ 0.1994],\n",
            "        [-0.0900],\n",
            "        [-0.3848],\n",
            "        [-0.3836]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3307],\n",
            "        [-0.2854],\n",
            "        [-0.3434],\n",
            "        [-0.2130],\n",
            "        [-0.1829],\n",
            "        [-0.0771],\n",
            "        [ 0.1704],\n",
            "        [ 0.3380],\n",
            "        [ 0.0494],\n",
            "        [-0.3832],\n",
            "        [-0.4241],\n",
            "        [-0.2850]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2842],\n",
            "        [-0.3121],\n",
            "        [-0.2155],\n",
            "        [-0.2068],\n",
            "        [-0.1397],\n",
            "        [ 0.1085],\n",
            "        [ 0.3682],\n",
            "        [ 0.2142],\n",
            "        [-0.2731],\n",
            "        [-0.4647],\n",
            "        [-0.2766],\n",
            "        [-0.2299]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3134],\n",
            "        [-0.1939],\n",
            "        [-0.2080],\n",
            "        [-0.1692],\n",
            "        [ 0.0430],\n",
            "        [ 0.3117],\n",
            "        [ 0.2976],\n",
            "        [-0.0813],\n",
            "        [-0.4605],\n",
            "        [-0.2997],\n",
            "        [-0.2118],\n",
            "        [-0.2046]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1960],\n",
            "        [-0.1791],\n",
            "        [-0.1799],\n",
            "        [-0.0004],\n",
            "        [ 0.2227],\n",
            "        [ 0.2685],\n",
            "        [ 0.0909],\n",
            "        [-0.3200],\n",
            "        [-0.3877],\n",
            "        [-0.1560],\n",
            "        [-0.2251],\n",
            "        [-0.1850]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1874],\n",
            "        [-0.1730],\n",
            "        [-0.0238],\n",
            "        [ 0.1732],\n",
            "        [ 0.2225],\n",
            "        [ 0.1509],\n",
            "        [-0.1730],\n",
            "        [-0.4116],\n",
            "        [-0.1197],\n",
            "        [-0.2238],\n",
            "        [-0.1962],\n",
            "        [-0.0636]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1824],\n",
            "        [-0.0219],\n",
            "        [ 0.1462],\n",
            "        [ 0.1750],\n",
            "        [ 0.1329],\n",
            "        [-0.0856],\n",
            "        [-0.3626],\n",
            "        [-0.1220],\n",
            "        [-0.2009],\n",
            "        [-0.2062],\n",
            "        [-0.0648],\n",
            "        [-0.0366]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0313],\n",
            "        [ 0.1442],\n",
            "        [ 0.1404],\n",
            "        [ 0.0855],\n",
            "        [-0.0743],\n",
            "        [-0.2981],\n",
            "        [-0.1265],\n",
            "        [-0.1723],\n",
            "        [-0.1965],\n",
            "        [-0.0469],\n",
            "        [-0.0166],\n",
            "        [ 0.0883]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1275],\n",
            "        [ 0.1104],\n",
            "        [ 0.0443],\n",
            "        [-0.0856],\n",
            "        [-0.2640],\n",
            "        [-0.1162],\n",
            "        [-0.1439],\n",
            "        [-0.1708],\n",
            "        [-0.0135],\n",
            "        [ 0.0146],\n",
            "        [ 0.0990],\n",
            "        [ 0.3344]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0751],\n",
            "        [-0.0039],\n",
            "        [-0.1007],\n",
            "        [-0.2430],\n",
            "        [-0.0989],\n",
            "        [-0.1047],\n",
            "        [-0.1389],\n",
            "        [ 0.0106],\n",
            "        [ 0.0081],\n",
            "        [ 0.0399],\n",
            "        [ 0.2305],\n",
            "        [ 0.3360]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0370],\n",
            "        [-0.1382],\n",
            "        [-0.2554],\n",
            "        [-0.1097],\n",
            "        [-0.0907],\n",
            "        [-0.0847],\n",
            "        [ 0.0806],\n",
            "        [ 0.0448],\n",
            "        [-0.0013],\n",
            "        [ 0.1382],\n",
            "        [ 0.2227],\n",
            "        [ 0.1470]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1623],\n",
            "        [-0.2729],\n",
            "        [-0.1396],\n",
            "        [-0.1175],\n",
            "        [-0.0792],\n",
            "        [ 0.1296],\n",
            "        [ 0.1227],\n",
            "        [ 0.0413],\n",
            "        [ 0.1384],\n",
            "        [ 0.2003],\n",
            "        [ 0.0914],\n",
            "        [-0.0598]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2871],\n",
            "        [-0.1408],\n",
            "        [-0.1364],\n",
            "        [-0.1102],\n",
            "        [ 0.0947],\n",
            "        [ 0.1407],\n",
            "        [ 0.1365],\n",
            "        [ 0.2314],\n",
            "        [ 0.2534],\n",
            "        [ 0.0665],\n",
            "        [-0.1594],\n",
            "        [-0.1711]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1487],\n",
            "        [-0.1130],\n",
            "        [-0.1299],\n",
            "        [ 0.0419],\n",
            "        [ 0.0757],\n",
            "        [ 0.1490],\n",
            "        [ 0.3386],\n",
            "        [ 0.3848],\n",
            "        [ 0.1310],\n",
            "        [-0.2395],\n",
            "        [-0.2678],\n",
            "        [-0.0860]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1289],\n",
            "        [-0.1348],\n",
            "        [ 0.0064],\n",
            "        [ 0.0321],\n",
            "        [ 0.1242],\n",
            "        [ 0.3748],\n",
            "        [ 0.4982],\n",
            "        [ 0.2562],\n",
            "        [-0.2654],\n",
            "        [-0.3571],\n",
            "        [-0.0965],\n",
            "        [-0.0635]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1527],\n",
            "        [-0.0056],\n",
            "        [-0.0006],\n",
            "        [ 0.0801],\n",
            "        [ 0.3397],\n",
            "        [ 0.5361],\n",
            "        [ 0.4104],\n",
            "        [-0.1588],\n",
            "        [-0.4458],\n",
            "        [-0.1092],\n",
            "        [-0.0788],\n",
            "        [-0.0334]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0211],\n",
            "        [-0.0087],\n",
            "        [ 0.0383],\n",
            "        [ 0.2722],\n",
            "        [ 0.4793],\n",
            "        [ 0.4872],\n",
            "        [ 0.0686],\n",
            "        [-0.4172],\n",
            "        [-0.2004],\n",
            "        [-0.0595],\n",
            "        [-0.0648],\n",
            "        [-0.0307]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0341],\n",
            "        [ 0.0065],\n",
            "        [ 0.2167],\n",
            "        [ 0.4177],\n",
            "        [ 0.4948],\n",
            "        [ 0.2360],\n",
            "        [-0.2733],\n",
            "        [-0.2924],\n",
            "        [-0.0272],\n",
            "        [-0.0907],\n",
            "        [-0.0504],\n",
            "        [ 0.1158]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0180],\n",
            "        [ 0.1814],\n",
            "        [ 0.3549],\n",
            "        [ 0.4363],\n",
            "        [ 0.2837],\n",
            "        [-0.1064],\n",
            "        [-0.2934],\n",
            "        [-0.0214],\n",
            "        [-0.0890],\n",
            "        [-0.0640],\n",
            "        [ 0.1114],\n",
            "        [ 0.1658]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1593],\n",
            "        [ 0.3124],\n",
            "        [ 0.3687],\n",
            "        [ 0.2478],\n",
            "        [-0.0305],\n",
            "        [-0.2229],\n",
            "        [-0.0325],\n",
            "        [-0.0625],\n",
            "        [-0.0550],\n",
            "        [ 0.1377],\n",
            "        [ 0.2050],\n",
            "        [ 0.3696]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2764],\n",
            "        [ 0.3052],\n",
            "        [ 0.2180],\n",
            "        [ 0.0128],\n",
            "        [-0.1846],\n",
            "        [-0.0310],\n",
            "        [-0.0406],\n",
            "        [-0.0559],\n",
            "        [ 0.1498],\n",
            "        [ 0.2115],\n",
            "        [ 0.3570],\n",
            "        [ 0.6586]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2517],\n",
            "        [ 0.1541],\n",
            "        [ 0.0373],\n",
            "        [-0.1245],\n",
            "        [-0.0156],\n",
            "        [ 0.0030],\n",
            "        [-0.0587],\n",
            "        [ 0.1392],\n",
            "        [ 0.1546],\n",
            "        [ 0.2265],\n",
            "        [ 0.4703],\n",
            "        [ 0.5909]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0979],\n",
            "        [-0.0194],\n",
            "        [-0.1089],\n",
            "        [ 0.0103],\n",
            "        [ 0.0497],\n",
            "        [ 0.0031],\n",
            "        [ 0.1931],\n",
            "        [ 0.1403],\n",
            "        [ 0.0965],\n",
            "        [ 0.2545],\n",
            "        [ 0.3521],\n",
            "        [ 0.3018]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0603],\n",
            "        [-0.1511],\n",
            "        [-0.0222],\n",
            "        [ 0.0317],\n",
            "        [ 0.0401],\n",
            "        [ 0.2784],\n",
            "        [ 0.2276],\n",
            "        [ 0.1160],\n",
            "        [ 0.2200],\n",
            "        [ 0.2984],\n",
            "        [ 0.2185],\n",
            "        [ 0.0532]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1766],\n",
            "        [-0.0463],\n",
            "        [-0.0053],\n",
            "        [ 0.0083],\n",
            "        [ 0.2636],\n",
            "        [ 0.2764],\n",
            "        [ 0.2304],\n",
            "        [ 0.3290],\n",
            "        [ 0.3556],\n",
            "        [ 0.1809],\n",
            "        [-0.0774],\n",
            "        [-0.1208]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0609],\n",
            "        [-0.0089],\n",
            "        [-0.0267],\n",
            "        [ 0.2011],\n",
            "        [ 0.2293],\n",
            "        [ 0.2791],\n",
            "        [ 0.4614],\n",
            "        [ 0.4894],\n",
            "        [ 0.2304],\n",
            "        [-0.1648],\n",
            "        [-0.2116],\n",
            "        [ 0.0592]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0319],\n",
            "        [-0.0514],\n",
            "        [ 0.1509],\n",
            "        [ 0.1821],\n",
            "        [ 0.2763],\n",
            "        [ 0.5319],\n",
            "        [ 0.6277],\n",
            "        [ 0.3550],\n",
            "        [-0.2177],\n",
            "        [-0.3164],\n",
            "        [ 0.0488],\n",
            "        [ 0.0935]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0784],\n",
            "        [ 0.1168],\n",
            "        [ 0.1346],\n",
            "        [ 0.2345],\n",
            "        [ 0.5205],\n",
            "        [ 0.7018],\n",
            "        [ 0.5283],\n",
            "        [-0.1483],\n",
            "        [-0.4208],\n",
            "        [ 0.0335],\n",
            "        [ 0.0714],\n",
            "        [ 0.0870]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0964],\n",
            "        [ 0.1072],\n",
            "        [ 0.1785],\n",
            "        [ 0.4435],\n",
            "        [ 0.6540],\n",
            "        [ 0.6331],\n",
            "        [ 0.0848],\n",
            "        [-0.4060],\n",
            "        [-0.0605],\n",
            "        [ 0.0906],\n",
            "        [ 0.0693],\n",
            "        [ 0.1082]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0700],\n",
            "        [ 0.1243],\n",
            "        [ 0.3769],\n",
            "        [ 0.5990],\n",
            "        [ 0.6763],\n",
            "        [ 0.2754],\n",
            "        [-0.3220],\n",
            "        [-0.1606],\n",
            "        [ 0.0990],\n",
            "        [ 0.0398],\n",
            "        [ 0.0784],\n",
            "        [ 0.2035]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0898],\n",
            "        [ 0.3183],\n",
            "        [ 0.5176],\n",
            "        [ 0.6201],\n",
            "        [ 0.3626],\n",
            "        [-0.1418],\n",
            "        [-0.1895],\n",
            "        [ 0.1000],\n",
            "        [ 0.0413],\n",
            "        [ 0.0705],\n",
            "        [ 0.1979],\n",
            "        [ 0.2329]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2882],\n",
            "        [ 0.4530],\n",
            "        [ 0.5419],\n",
            "        [ 0.3503],\n",
            "        [-0.0289],\n",
            "        [-0.1359],\n",
            "        [ 0.0935],\n",
            "        [ 0.0658],\n",
            "        [ 0.0801],\n",
            "        [ 0.2095],\n",
            "        [ 0.2566],\n",
            "        [ 0.4373]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4050],\n",
            "        [ 0.4724],\n",
            "        [ 0.3583],\n",
            "        [ 0.0646],\n",
            "        [-0.1589],\n",
            "        [ 0.0611],\n",
            "        [ 0.0477],\n",
            "        [ 0.0401],\n",
            "        [ 0.1857],\n",
            "        [ 0.2352],\n",
            "        [ 0.4235],\n",
            "        [ 0.8231]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4066],\n",
            "        [ 0.2997],\n",
            "        [ 0.1579],\n",
            "        [-0.0701],\n",
            "        [ 0.0242],\n",
            "        [ 0.0595],\n",
            "        [-0.0163],\n",
            "        [ 0.1422],\n",
            "        [ 0.1608],\n",
            "        [ 0.2978],\n",
            "        [ 0.6284],\n",
            "        [ 0.8939]], grad_fn=<AddmmBackward>)\n",
            "tensor([[0.2254],\n",
            "        [0.1024],\n",
            "        [0.0082],\n",
            "        [0.0994],\n",
            "        [0.1220],\n",
            "        [0.0276],\n",
            "        [0.1507],\n",
            "        [0.0834],\n",
            "        [0.1022],\n",
            "        [0.3080],\n",
            "        [0.4588],\n",
            "        [0.4682]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0491],\n",
            "        [-0.0500],\n",
            "        [ 0.0799],\n",
            "        [ 0.1265],\n",
            "        [ 0.0899],\n",
            "        [ 0.2457],\n",
            "        [ 0.1455],\n",
            "        [ 0.0914],\n",
            "        [ 0.2517],\n",
            "        [ 0.3507],\n",
            "        [ 0.3060],\n",
            "        [ 0.0642]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0859],\n",
            "        [ 0.0334],\n",
            "        [ 0.0752],\n",
            "        [ 0.0675],\n",
            "        [ 0.2638],\n",
            "        [ 0.2134],\n",
            "        [ 0.1846],\n",
            "        [ 0.3407],\n",
            "        [ 0.4004],\n",
            "        [ 0.2585],\n",
            "        [-0.0932],\n",
            "        [-0.1867]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0096],\n",
            "        [ 0.0484],\n",
            "        [ 0.0200],\n",
            "        [ 0.2054],\n",
            "        [ 0.1924],\n",
            "        [ 0.2417],\n",
            "        [ 0.4420],\n",
            "        [ 0.5186],\n",
            "        [ 0.3266],\n",
            "        [-0.1721],\n",
            "        [-0.2941],\n",
            "        [ 0.0159]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0200],\n",
            "        [-0.0195],\n",
            "        [ 0.1505],\n",
            "        [ 0.1534],\n",
            "        [ 0.2540],\n",
            "        [ 0.5083],\n",
            "        [ 0.6388],\n",
            "        [ 0.4452],\n",
            "        [-0.2217],\n",
            "        [-0.4009],\n",
            "        [ 0.0200],\n",
            "        [ 0.0397]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0491],\n",
            "        [ 0.1066],\n",
            "        [ 0.1024],\n",
            "        [ 0.2168],\n",
            "        [ 0.5019],\n",
            "        [ 0.7075],\n",
            "        [ 0.6014],\n",
            "        [-0.1575],\n",
            "        [-0.4827],\n",
            "        [ 0.0179],\n",
            "        [ 0.0258],\n",
            "        [ 0.0437]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0836],\n",
            "        [ 0.0702],\n",
            "        [ 0.1607],\n",
            "        [ 0.4284],\n",
            "        [ 0.6619],\n",
            "        [ 0.6886],\n",
            "        [ 0.0463],\n",
            "        [-0.4515],\n",
            "        [-0.0569],\n",
            "        [ 0.0498],\n",
            "        [ 0.0376],\n",
            "        [ 0.0755]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0419],\n",
            "        [ 0.1110],\n",
            "        [ 0.3600],\n",
            "        [ 0.5968],\n",
            "        [ 0.7103],\n",
            "        [ 0.2270],\n",
            "        [-0.3398],\n",
            "        [-0.1409],\n",
            "        [ 0.0731],\n",
            "        [ 0.0316],\n",
            "        [ 0.0673],\n",
            "        [ 0.2339]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0870],\n",
            "        [ 0.3097],\n",
            "        [ 0.5181],\n",
            "        [ 0.6426],\n",
            "        [ 0.3063],\n",
            "        [-0.1493],\n",
            "        [-0.1583],\n",
            "        [ 0.0834],\n",
            "        [ 0.0545],\n",
            "        [ 0.0821],\n",
            "        [ 0.2501],\n",
            "        [ 0.3022]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2906],\n",
            "        [ 0.4616],\n",
            "        [ 0.5699],\n",
            "        [ 0.3085],\n",
            "        [-0.0213],\n",
            "        [-0.0965],\n",
            "        [ 0.0914],\n",
            "        [ 0.0990],\n",
            "        [ 0.1141],\n",
            "        [ 0.2836],\n",
            "        [ 0.3454],\n",
            "        [ 0.5411]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4343],\n",
            "        [ 0.5096],\n",
            "        [ 0.3169],\n",
            "        [ 0.0639],\n",
            "        [-0.1075],\n",
            "        [ 0.0759],\n",
            "        [ 0.1003],\n",
            "        [ 0.1017],\n",
            "        [ 0.2857],\n",
            "        [ 0.3505],\n",
            "        [ 0.5500],\n",
            "        [ 0.8372]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4698],\n",
            "        [ 0.2680],\n",
            "        [ 0.1594],\n",
            "        [-0.0619],\n",
            "        [ 0.0299],\n",
            "        [ 0.1068],\n",
            "        [ 0.0510],\n",
            "        [ 0.2578],\n",
            "        [ 0.2961],\n",
            "        [ 0.4503],\n",
            "        [ 0.6723],\n",
            "        [ 0.8991]], grad_fn=<AddmmBackward>)\n",
            "tensor([[0.2120],\n",
            "        [0.1189],\n",
            "        [0.0180],\n",
            "        [0.0956],\n",
            "        [0.1743],\n",
            "        [0.0890],\n",
            "        [0.2581],\n",
            "        [0.1874],\n",
            "        [0.1884],\n",
            "        [0.2918],\n",
            "        [0.4619],\n",
            "        [0.5365]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0849],\n",
            "        [-0.0316],\n",
            "        [ 0.0858],\n",
            "        [ 0.1828],\n",
            "        [ 0.1506],\n",
            "        [ 0.3590],\n",
            "        [ 0.2583],\n",
            "        [ 0.1802],\n",
            "        [ 0.2268],\n",
            "        [ 0.3876],\n",
            "        [ 0.4476],\n",
            "        [ 0.3936]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0624],\n",
            "        [ 0.0432],\n",
            "        [ 0.1408],\n",
            "        [ 0.1463],\n",
            "        [ 0.4059],\n",
            "        [ 0.3604],\n",
            "        [ 0.2945],\n",
            "        [ 0.2946],\n",
            "        [ 0.3982],\n",
            "        [ 0.3750],\n",
            "        [ 0.2429],\n",
            "        [ 0.2200]], grad_fn=<AddmmBackward>)\n",
            "tensor([[0.0219],\n",
            "        [0.1162],\n",
            "        [0.1077],\n",
            "        [0.3601],\n",
            "        [0.3721],\n",
            "        [0.4102],\n",
            "        [0.4488],\n",
            "        [0.5036],\n",
            "        [0.3712],\n",
            "        [0.1318],\n",
            "        [0.0841],\n",
            "        [0.2850]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7007],\n",
            "        [-0.6944],\n",
            "        [-0.6952],\n",
            "        [-0.7434],\n",
            "        [-0.7773],\n",
            "        [-0.7118],\n",
            "        [-0.5650],\n",
            "        [-0.4071],\n",
            "        [-0.4733],\n",
            "        [-0.7093],\n",
            "        [-0.7238],\n",
            "        [-0.7473]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6842],\n",
            "        [-0.6491],\n",
            "        [-0.7148],\n",
            "        [-0.7612],\n",
            "        [-0.7422],\n",
            "        [-0.6860],\n",
            "        [-0.5613],\n",
            "        [-0.4423],\n",
            "        [-0.5596],\n",
            "        [-0.7443],\n",
            "        [-0.6581],\n",
            "        [-0.7866]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6429],\n",
            "        [-0.6668],\n",
            "        [-0.7467],\n",
            "        [-0.7243],\n",
            "        [-0.7247],\n",
            "        [-0.6813],\n",
            "        [-0.5921],\n",
            "        [-0.5106],\n",
            "        [-0.6563],\n",
            "        [-0.6355],\n",
            "        [-0.7496],\n",
            "        [-0.7334]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6579],\n",
            "        [-0.7050],\n",
            "        [-0.7067],\n",
            "        [-0.7085],\n",
            "        [-0.7225],\n",
            "        [-0.7129],\n",
            "        [-0.6478],\n",
            "        [-0.6078],\n",
            "        [-0.6020],\n",
            "        [-0.6990],\n",
            "        [-0.7545],\n",
            "        [-0.7092]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6910],\n",
            "        [-0.6671],\n",
            "        [-0.6806],\n",
            "        [-0.7183],\n",
            "        [-0.7609],\n",
            "        [-0.7829],\n",
            "        [-0.7428],\n",
            "        [-0.5903],\n",
            "        [-0.6574],\n",
            "        [-0.6931],\n",
            "        [-0.7165],\n",
            "        [-0.7491]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6528],\n",
            "        [-0.6343],\n",
            "        [-0.6956],\n",
            "        [-0.7632],\n",
            "        [-0.8388],\n",
            "        [-0.8800],\n",
            "        [-0.7562],\n",
            "        [-0.6828],\n",
            "        [-0.5672],\n",
            "        [-0.5895],\n",
            "        [-0.7179],\n",
            "        [-0.7874]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6164],\n",
            "        [-0.6469],\n",
            "        [-0.7497],\n",
            "        [-0.8346],\n",
            "        [-0.9251],\n",
            "        [-0.8849],\n",
            "        [-0.8495],\n",
            "        [-0.6317],\n",
            "        [-0.4393],\n",
            "        [-0.5550],\n",
            "        [-0.7684],\n",
            "        [-0.6721]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6233],\n",
            "        [-0.7046],\n",
            "        [-0.8252],\n",
            "        [-0.9108],\n",
            "        [-0.9228],\n",
            "        [-0.9555],\n",
            "        [-0.8148],\n",
            "        [-0.5531],\n",
            "        [-0.3952],\n",
            "        [-0.6301],\n",
            "        [-0.6299],\n",
            "        [-0.6326]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6714],\n",
            "        [-0.7831],\n",
            "        [-0.8964],\n",
            "        [-0.8969],\n",
            "        [-0.9812],\n",
            "        [-0.9240],\n",
            "        [-0.7584],\n",
            "        [-0.5090],\n",
            "        [-0.4248],\n",
            "        [-0.5850],\n",
            "        [-0.5353],\n",
            "        [-0.7217]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7369],\n",
            "        [-0.8560],\n",
            "        [-0.8617],\n",
            "        [-0.9486],\n",
            "        [-0.9520],\n",
            "        [-0.8949],\n",
            "        [-0.7404],\n",
            "        [-0.4931],\n",
            "        [-0.3502],\n",
            "        [-0.5361],\n",
            "        [-0.6497],\n",
            "        [-0.7786]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7968],\n",
            "        [-0.8200],\n",
            "        [-0.8953],\n",
            "        [-0.9274],\n",
            "        [-0.9311],\n",
            "        [-0.9130],\n",
            "        [-0.7456],\n",
            "        [-0.3675],\n",
            "        [-0.3240],\n",
            "        [-0.6205],\n",
            "        [-0.7520],\n",
            "        [-0.8696]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7575],\n",
            "        [-0.8449],\n",
            "        [-0.8698],\n",
            "        [-0.9004],\n",
            "        [-0.9589],\n",
            "        [-0.9436],\n",
            "        [-0.6582],\n",
            "        [-0.3151],\n",
            "        [-0.3638],\n",
            "        [-0.7367],\n",
            "        [-0.8160],\n",
            "        [-0.9356]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7744],\n",
            "        [-0.8148],\n",
            "        [-0.8295],\n",
            "        [-0.9300],\n",
            "        [-0.9866],\n",
            "        [-0.8724],\n",
            "        [-0.6089],\n",
            "        [-0.3166],\n",
            "        [-0.4285],\n",
            "        [-0.8572],\n",
            "        [-0.8078],\n",
            "        [-0.8816]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7406],\n",
            "        [-0.7623],\n",
            "        [-0.8590],\n",
            "        [-0.9568],\n",
            "        [-0.9242],\n",
            "        [-0.8331],\n",
            "        [-0.6125],\n",
            "        [-0.3445],\n",
            "        [-0.5723],\n",
            "        [-0.8743],\n",
            "        [-0.7053],\n",
            "        [-0.9029]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6898],\n",
            "        [-0.7864],\n",
            "        [-0.8968],\n",
            "        [-0.8796],\n",
            "        [-0.8766],\n",
            "        [-0.8087],\n",
            "        [-0.6145],\n",
            "        [-0.4632],\n",
            "        [-0.7382],\n",
            "        [-0.6362],\n",
            "        [-0.8523],\n",
            "        [-0.8316]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7110],\n",
            "        [-0.8257],\n",
            "        [-0.8062],\n",
            "        [-0.8224],\n",
            "        [-0.8375],\n",
            "        [-0.7897],\n",
            "        [-0.6663],\n",
            "        [-0.6239],\n",
            "        [-0.6374],\n",
            "        [-0.7189],\n",
            "        [-0.8832],\n",
            "        [-0.7387]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7464],\n",
            "        [-0.7327],\n",
            "        [-0.7317],\n",
            "        [-0.7998],\n",
            "        [-0.8327],\n",
            "        [-0.8553],\n",
            "        [-0.7772],\n",
            "        [-0.5721],\n",
            "        [-0.6768],\n",
            "        [-0.8220],\n",
            "        [-0.7588],\n",
            "        [-0.8211]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6590],\n",
            "        [-0.6394],\n",
            "        [-0.7155],\n",
            "        [-0.7989],\n",
            "        [-0.9033],\n",
            "        [-0.9446],\n",
            "        [-0.7394],\n",
            "        [-0.6433],\n",
            "        [-0.6338],\n",
            "        [-0.6193],\n",
            "        [-0.7803],\n",
            "        [-0.7392]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5814],\n",
            "        [-0.6273],\n",
            "        [-0.7433],\n",
            "        [-0.8701],\n",
            "        [-0.9751],\n",
            "        [-0.8804],\n",
            "        [-0.7931],\n",
            "        [-0.5765],\n",
            "        [-0.3563],\n",
            "        [-0.6285],\n",
            "        [-0.6988],\n",
            "        [-0.7277]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5776],\n",
            "        [-0.6657],\n",
            "        [-0.8283],\n",
            "        [-0.9336],\n",
            "        [-0.9022],\n",
            "        [-0.8941],\n",
            "        [-0.7172],\n",
            "        [-0.3465],\n",
            "        [-0.3999],\n",
            "        [-0.6174],\n",
            "        [-0.6100],\n",
            "        [-0.6689]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6158],\n",
            "        [-0.7565],\n",
            "        [-0.8928],\n",
            "        [-0.8493],\n",
            "        [-0.9055],\n",
            "        [-0.8200],\n",
            "        [-0.5267],\n",
            "        [-0.3471],\n",
            "        [-0.4147],\n",
            "        [-0.5450],\n",
            "        [-0.5972],\n",
            "        [-0.6449]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6998],\n",
            "        [-0.8275],\n",
            "        [-0.7897],\n",
            "        [-0.8513],\n",
            "        [-0.8396],\n",
            "        [-0.6765],\n",
            "        [-0.5144],\n",
            "        [-0.2713],\n",
            "        [-0.4792],\n",
            "        [-0.4550],\n",
            "        [-0.6517],\n",
            "        [-0.6589]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7632],\n",
            "        [-0.7255],\n",
            "        [-0.7736],\n",
            "        [-0.8068],\n",
            "        [-0.7239],\n",
            "        [-0.6977],\n",
            "        [-0.4140],\n",
            "        [-0.3070],\n",
            "        [-0.3991],\n",
            "        [-0.5174],\n",
            "        [-0.6977],\n",
            "        [-0.7289]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6712],\n",
            "        [-0.7004],\n",
            "        [-0.7436],\n",
            "        [-0.6955],\n",
            "        [-0.7597],\n",
            "        [-0.6187],\n",
            "        [-0.4348],\n",
            "        [-0.2245],\n",
            "        [-0.4188],\n",
            "        [-0.6147],\n",
            "        [-0.7548],\n",
            "        [-0.7791]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6518],\n",
            "        [-0.6774],\n",
            "        [-0.6345],\n",
            "        [-0.7361],\n",
            "        [-0.6792],\n",
            "        [-0.6065],\n",
            "        [-0.3370],\n",
            "        [-0.2677],\n",
            "        [-0.5165],\n",
            "        [-0.6840],\n",
            "        [-0.7650],\n",
            "        [-0.7070]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6326],\n",
            "        [-0.5669],\n",
            "        [-0.6846],\n",
            "        [-0.6689],\n",
            "        [-0.6687],\n",
            "        [-0.5105],\n",
            "        [-0.3609],\n",
            "        [-0.3386],\n",
            "        [-0.6185],\n",
            "        [-0.6799],\n",
            "        [-0.6875],\n",
            "        [-0.6888]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5325],\n",
            "        [-0.6152],\n",
            "        [-0.6358],\n",
            "        [-0.6512],\n",
            "        [-0.5813],\n",
            "        [-0.5108],\n",
            "        [-0.4015],\n",
            "        [-0.4632],\n",
            "        [-0.6696],\n",
            "        [-0.5569],\n",
            "        [-0.7090],\n",
            "        [-0.6224]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5836],\n",
            "        [-0.5819],\n",
            "        [-0.6161],\n",
            "        [-0.5712],\n",
            "        [-0.5651],\n",
            "        [-0.5162],\n",
            "        [-0.4907],\n",
            "        [-0.5875],\n",
            "        [-0.5324],\n",
            "        [-0.6439],\n",
            "        [-0.6450],\n",
            "        [-0.5915]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5513],\n",
            "        [-0.5565],\n",
            "        [-0.5335],\n",
            "        [-0.5614],\n",
            "        [-0.5827],\n",
            "        [-0.6006],\n",
            "        [-0.6060],\n",
            "        [-0.5136],\n",
            "        [-0.5683],\n",
            "        [-0.6365],\n",
            "        [-0.5813],\n",
            "        [-0.6177]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5301],\n",
            "        [-0.4765],\n",
            "        [-0.5295],\n",
            "        [-0.5890],\n",
            "        [-0.6585],\n",
            "        [-0.6912],\n",
            "        [-0.5651],\n",
            "        [-0.5418],\n",
            "        [-0.5358],\n",
            "        [-0.5319],\n",
            "        [-0.5948],\n",
            "        [-0.5746]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4552],\n",
            "        [-0.4703],\n",
            "        [-0.5714],\n",
            "        [-0.6606],\n",
            "        [-0.7339],\n",
            "        [-0.6503],\n",
            "        [-0.5998],\n",
            "        [-0.4756],\n",
            "        [-0.3922],\n",
            "        [-0.5121],\n",
            "        [-0.5724],\n",
            "        [-0.4703]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4541],\n",
            "        [-0.5241],\n",
            "        [-0.6520],\n",
            "        [-0.7269],\n",
            "        [-0.6860],\n",
            "        [-0.6652],\n",
            "        [-0.5295],\n",
            "        [-0.3470],\n",
            "        [-0.3920],\n",
            "        [-0.5103],\n",
            "        [-0.4318],\n",
            "        [-0.4845]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5049],\n",
            "        [-0.6070],\n",
            "        [-0.7144],\n",
            "        [-0.6697],\n",
            "        [-0.6935],\n",
            "        [-0.6012],\n",
            "        [-0.4255],\n",
            "        [-0.3381],\n",
            "        [-0.3995],\n",
            "        [-0.3438],\n",
            "        [-0.4651],\n",
            "        [-0.4401]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5811],\n",
            "        [-0.6711],\n",
            "        [-0.6446],\n",
            "        [-0.6744],\n",
            "        [-0.6403],\n",
            "        [-0.5312],\n",
            "        [-0.4203],\n",
            "        [-0.3090],\n",
            "        [-0.2484],\n",
            "        [-0.3667],\n",
            "        [-0.4653],\n",
            "        [-0.5601]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6368],\n",
            "        [-0.5988],\n",
            "        [-0.6328],\n",
            "        [-0.6309],\n",
            "        [-0.5854],\n",
            "        [-0.5498],\n",
            "        [-0.3858],\n",
            "        [-0.1603],\n",
            "        [-0.2398],\n",
            "        [-0.3850],\n",
            "        [-0.5999],\n",
            "        [-0.6123]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5679],\n",
            "        [-0.5791],\n",
            "        [-0.5944],\n",
            "        [-0.5789],\n",
            "        [-0.6145],\n",
            "        [-0.5291],\n",
            "        [-0.2644],\n",
            "        [-0.1378],\n",
            "        [-0.1969],\n",
            "        [-0.5333],\n",
            "        [-0.6433],\n",
            "        [-0.6403]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5508],\n",
            "        [-0.5459],\n",
            "        [-0.5456],\n",
            "        [-0.6115],\n",
            "        [-0.5894],\n",
            "        [-0.4094],\n",
            "        [-0.2326],\n",
            "        [-0.0638],\n",
            "        [-0.3681],\n",
            "        [-0.5947],\n",
            "        [-0.6126],\n",
            "        [-0.5710]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5198],\n",
            "        [-0.4969],\n",
            "        [-0.5862],\n",
            "        [-0.5911],\n",
            "        [-0.4798],\n",
            "        [-0.3737],\n",
            "        [-0.1481],\n",
            "        [-0.2124],\n",
            "        [-0.4658],\n",
            "        [-0.5548],\n",
            "        [-0.5366],\n",
            "        [-0.5814]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4748],\n",
            "        [-0.5404],\n",
            "        [-0.5754],\n",
            "        [-0.4781],\n",
            "        [-0.4424],\n",
            "        [-0.2831],\n",
            "        [-0.2573],\n",
            "        [-0.3137],\n",
            "        [-0.5356],\n",
            "        [-0.4374],\n",
            "        [-0.5956],\n",
            "        [-0.5595]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5161],\n",
            "        [-0.5347],\n",
            "        [-0.4502],\n",
            "        [-0.4400],\n",
            "        [-0.3482],\n",
            "        [-0.3614],\n",
            "        [-0.3211],\n",
            "        [-0.4825],\n",
            "        [-0.3976],\n",
            "        [-0.5510],\n",
            "        [-0.5712],\n",
            "        [-0.4263]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5083],\n",
            "        [-0.4025],\n",
            "        [-0.4033],\n",
            "        [-0.3580],\n",
            "        [-0.4299],\n",
            "        [-0.4166],\n",
            "        [-0.4920],\n",
            "        [-0.3995],\n",
            "        [-0.4859],\n",
            "        [-0.5604],\n",
            "        [-0.4041],\n",
            "        [-0.4002]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3853],\n",
            "        [-0.3505],\n",
            "        [-0.3379],\n",
            "        [-0.4486],\n",
            "        [-0.4854],\n",
            "        [-0.5577],\n",
            "        [-0.4425],\n",
            "        [-0.4662],\n",
            "        [-0.4908],\n",
            "        [-0.3382],\n",
            "        [-0.3425],\n",
            "        [-0.3187]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3437],\n",
            "        [-0.3048],\n",
            "        [-0.4487],\n",
            "        [-0.5074],\n",
            "        [-0.5967],\n",
            "        [-0.4992],\n",
            "        [-0.4925],\n",
            "        [-0.4439],\n",
            "        [-0.2411],\n",
            "        [-0.2579],\n",
            "        [-0.3239],\n",
            "        [-0.3318]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3019],\n",
            "        [-0.4206],\n",
            "        [-0.5174],\n",
            "        [-0.6049],\n",
            "        [-0.5394],\n",
            "        [-0.5381],\n",
            "        [-0.4618],\n",
            "        [-0.1956],\n",
            "        [-0.1573],\n",
            "        [-0.2789],\n",
            "        [-0.3546],\n",
            "        [-0.3160]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4173],\n",
            "        [-0.4967],\n",
            "        [-0.6058],\n",
            "        [-0.5442],\n",
            "        [-0.5673],\n",
            "        [-0.5059],\n",
            "        [-0.2370],\n",
            "        [-0.1169],\n",
            "        [-0.1823],\n",
            "        [-0.3030],\n",
            "        [-0.2965],\n",
            "        [-0.3508]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4808],\n",
            "        [-0.5727],\n",
            "        [-0.5327],\n",
            "        [-0.5613],\n",
            "        [-0.5486],\n",
            "        [-0.3398],\n",
            "        [-0.1995],\n",
            "        [-0.0872],\n",
            "        [-0.1603],\n",
            "        [-0.2116],\n",
            "        [-0.3345],\n",
            "        [-0.5191]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5479],\n",
            "        [-0.4951],\n",
            "        [-0.5331],\n",
            "        [-0.5476],\n",
            "        [-0.4015],\n",
            "        [-0.3280],\n",
            "        [-0.1585],\n",
            "        [-0.0373],\n",
            "        [-0.0913],\n",
            "        [-0.2387],\n",
            "        [-0.5279],\n",
            "        [-0.6188]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4714],\n",
            "        [-0.4843],\n",
            "        [-0.5245],\n",
            "        [-0.4017],\n",
            "        [-0.4023],\n",
            "        [-0.2998],\n",
            "        [-0.1046],\n",
            "        [ 0.0300],\n",
            "        [-0.0959],\n",
            "        [-0.4569],\n",
            "        [-0.6343],\n",
            "        [-0.6214]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4647],\n",
            "        [-0.4842],\n",
            "        [-0.3774],\n",
            "        [-0.4052],\n",
            "        [-0.3678],\n",
            "        [-0.2266],\n",
            "        [-0.0182],\n",
            "        [ 0.0186],\n",
            "        [-0.3403],\n",
            "        [-0.5831],\n",
            "        [-0.6184],\n",
            "        [-0.5229]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4653],\n",
            "        [-0.3369],\n",
            "        [-0.3783],\n",
            "        [-0.3843],\n",
            "        [-0.3027],\n",
            "        [-0.1427],\n",
            "        [-0.0089],\n",
            "        [-0.1995],\n",
            "        [-0.4838],\n",
            "        [-0.5872],\n",
            "        [-0.5048],\n",
            "        [-0.5415]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3258],\n",
            "        [-0.3327],\n",
            "        [-0.3785],\n",
            "        [-0.3259],\n",
            "        [-0.2323],\n",
            "        [-0.1227],\n",
            "        [-0.1792],\n",
            "        [-0.3393],\n",
            "        [-0.5629],\n",
            "        [-0.4398],\n",
            "        [-0.5448],\n",
            "        [-0.5740]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3291],\n",
            "        [-0.3541],\n",
            "        [-0.3286],\n",
            "        [-0.2554],\n",
            "        [-0.1859],\n",
            "        [-0.2246],\n",
            "        [-0.2936],\n",
            "        [-0.5174],\n",
            "        [-0.4051],\n",
            "        [-0.5152],\n",
            "        [-0.5828],\n",
            "        [-0.4211]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3502],\n",
            "        [-0.3050],\n",
            "        [-0.2543],\n",
            "        [-0.2126],\n",
            "        [-0.2797],\n",
            "        [-0.3241],\n",
            "        [-0.4927],\n",
            "        [-0.4032],\n",
            "        [-0.4732],\n",
            "        [-0.5870],\n",
            "        [-0.4073],\n",
            "        [-0.4439]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3010],\n",
            "        [-0.2261],\n",
            "        [-0.2120],\n",
            "        [-0.3089],\n",
            "        [-0.3749],\n",
            "        [-0.5132],\n",
            "        [-0.4225],\n",
            "        [-0.4611],\n",
            "        [-0.5627],\n",
            "        [-0.3759],\n",
            "        [-0.4066],\n",
            "        [-0.2805]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2278],\n",
            "        [-0.1922],\n",
            "        [-0.3211],\n",
            "        [-0.4044],\n",
            "        [-0.5409],\n",
            "        [-0.4559],\n",
            "        [-0.4751],\n",
            "        [-0.5318],\n",
            "        [-0.3197],\n",
            "        [-0.3413],\n",
            "        [-0.2386],\n",
            "        [-0.1217]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2002],\n",
            "        [-0.3129],\n",
            "        [-0.4237],\n",
            "        [-0.5551],\n",
            "        [-0.4868],\n",
            "        [-0.4995],\n",
            "        [-0.5233],\n",
            "        [-0.2724],\n",
            "        [-0.2672],\n",
            "        [-0.1998],\n",
            "        [-0.1535],\n",
            "        [-0.1041]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3227],\n",
            "        [-0.4191],\n",
            "        [-0.5648],\n",
            "        [-0.5024],\n",
            "        [-0.5252],\n",
            "        [-0.5394],\n",
            "        [-0.2706],\n",
            "        [-0.2166],\n",
            "        [-0.1396],\n",
            "        [-0.1397],\n",
            "        [-0.1285],\n",
            "        [-0.3095]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4147],\n",
            "        [-0.5421],\n",
            "        [-0.5032],\n",
            "        [-0.5273],\n",
            "        [-0.5722],\n",
            "        [-0.3420],\n",
            "        [-0.2662],\n",
            "        [-0.0716],\n",
            "        [-0.0176],\n",
            "        [-0.0440],\n",
            "        [-0.3124],\n",
            "        [-0.5592]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5231],\n",
            "        [-0.4700],\n",
            "        [-0.5042],\n",
            "        [-0.5717],\n",
            "        [-0.3960],\n",
            "        [-0.3718],\n",
            "        [-0.1447],\n",
            "        [ 0.0696],\n",
            "        [ 0.1046],\n",
            "        [-0.2157],\n",
            "        [-0.5637],\n",
            "        [-0.5994]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4483],\n",
            "        [-0.4521],\n",
            "        [-0.5509],\n",
            "        [-0.3960],\n",
            "        [-0.4391],\n",
            "        [-0.2857],\n",
            "        [-0.0266],\n",
            "        [ 0.2318],\n",
            "        [-0.0204],\n",
            "        [-0.4867],\n",
            "        [-0.5849],\n",
            "        [-0.4871]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4367],\n",
            "        [-0.5081],\n",
            "        [-0.3766],\n",
            "        [-0.4388],\n",
            "        [-0.3529],\n",
            "        [-0.1568],\n",
            "        [ 0.1638],\n",
            "        [ 0.1426],\n",
            "        [-0.3215],\n",
            "        [-0.5574],\n",
            "        [-0.4555],\n",
            "        [-0.4445]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4913],\n",
            "        [-0.3358],\n",
            "        [-0.4104],\n",
            "        [-0.3671],\n",
            "        [-0.2335],\n",
            "        [ 0.0221],\n",
            "        [ 0.1323],\n",
            "        [-0.1013],\n",
            "        [-0.4911],\n",
            "        [-0.4431],\n",
            "        [-0.4111],\n",
            "        [-0.4077]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3261],\n",
            "        [-0.3541],\n",
            "        [-0.3564],\n",
            "        [-0.2532],\n",
            "        [-0.0875],\n",
            "        [ 0.0021],\n",
            "        [-0.0255],\n",
            "        [-0.3002],\n",
            "        [-0.4875],\n",
            "        [-0.3192],\n",
            "        [-0.4218],\n",
            "        [-0.4048]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3522],\n",
            "        [-0.3281],\n",
            "        [-0.2511],\n",
            "        [-0.1152],\n",
            "        [-0.0678],\n",
            "        [-0.0656],\n",
            "        [-0.2146],\n",
            "        [-0.4589],\n",
            "        [-0.2885],\n",
            "        [-0.3990],\n",
            "        [-0.4146],\n",
            "        [-0.2892]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3262],\n",
            "        [-0.2180],\n",
            "        [-0.1092],\n",
            "        [-0.1007],\n",
            "        [-0.1323],\n",
            "        [-0.2252],\n",
            "        [-0.4136],\n",
            "        [-0.3008],\n",
            "        [-0.3561],\n",
            "        [-0.4142],\n",
            "        [-0.2760],\n",
            "        [-0.2515]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2216],\n",
            "        [-0.0808],\n",
            "        [-0.1081],\n",
            "        [-0.1739],\n",
            "        [-0.2680],\n",
            "        [-0.4037],\n",
            "        [-0.3086],\n",
            "        [-0.3278],\n",
            "        [-0.3898],\n",
            "        [-0.2448],\n",
            "        [-0.2144],\n",
            "        [-0.1274]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0918],\n",
            "        [-0.1004],\n",
            "        [-0.2012],\n",
            "        [-0.2984],\n",
            "        [-0.4139],\n",
            "        [-0.3168],\n",
            "        [-0.3104],\n",
            "        [-0.3475],\n",
            "        [-0.1907],\n",
            "        [-0.1608],\n",
            "        [-0.1133],\n",
            "        [ 0.0551]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1204],\n",
            "        [-0.2151],\n",
            "        [-0.3207],\n",
            "        [-0.4244],\n",
            "        [-0.3298],\n",
            "        [-0.2996],\n",
            "        [-0.3060],\n",
            "        [-0.1289],\n",
            "        [-0.1135],\n",
            "        [-0.1333],\n",
            "        [-0.0215],\n",
            "        [ 0.0816]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2341],\n",
            "        [-0.3259],\n",
            "        [-0.4388],\n",
            "        [-0.3515],\n",
            "        [-0.3189],\n",
            "        [-0.2940],\n",
            "        [-0.0790],\n",
            "        [-0.0453],\n",
            "        [-0.1171],\n",
            "        [-0.0523],\n",
            "        [ 0.0355],\n",
            "        [-0.1138]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3354],\n",
            "        [-0.4228],\n",
            "        [-0.3622],\n",
            "        [-0.3369],\n",
            "        [-0.3280],\n",
            "        [-0.1105],\n",
            "        [-0.0169],\n",
            "        [-0.0226],\n",
            "        [ 0.0178],\n",
            "        [ 0.0755],\n",
            "        [-0.1399],\n",
            "        [-0.3314]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4228],\n",
            "        [-0.3310],\n",
            "        [-0.3286],\n",
            "        [-0.3449],\n",
            "        [-0.1742],\n",
            "        [-0.0837],\n",
            "        [ 0.0178],\n",
            "        [ 0.1418],\n",
            "        [ 0.1797],\n",
            "        [-0.1089],\n",
            "        [-0.3884],\n",
            "        [-0.3831]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3315],\n",
            "        [-0.2792],\n",
            "        [-0.3396],\n",
            "        [-0.2021],\n",
            "        [-0.1678],\n",
            "        [-0.0557],\n",
            "        [ 0.1838],\n",
            "        [ 0.3266],\n",
            "        [ 0.0252],\n",
            "        [-0.3845],\n",
            "        [-0.4216],\n",
            "        [-0.2922]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2853],\n",
            "        [-0.3062],\n",
            "        [-0.2102],\n",
            "        [-0.1970],\n",
            "        [-0.1222],\n",
            "        [ 0.1313],\n",
            "        [ 0.3773],\n",
            "        [ 0.1930],\n",
            "        [-0.2845],\n",
            "        [-0.4544],\n",
            "        [-0.2804],\n",
            "        [-0.2376]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3143],\n",
            "        [-0.1877],\n",
            "        [-0.2036],\n",
            "        [-0.1568],\n",
            "        [ 0.0629],\n",
            "        [ 0.3327],\n",
            "        [ 0.2956],\n",
            "        [-0.0966],\n",
            "        [-0.4520],\n",
            "        [-0.2954],\n",
            "        [-0.2187],\n",
            "        [-0.2097]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1975],\n",
            "        [-0.1739],\n",
            "        [-0.1736],\n",
            "        [ 0.0134],\n",
            "        [ 0.2416],\n",
            "        [ 0.2836],\n",
            "        [ 0.0913],\n",
            "        [-0.3202],\n",
            "        [-0.3763],\n",
            "        [-0.1582],\n",
            "        [-0.2324],\n",
            "        [-0.1861]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1889],\n",
            "        [-0.1678],\n",
            "        [-0.0172],\n",
            "        [ 0.1853],\n",
            "        [ 0.2397],\n",
            "        [ 0.1693],\n",
            "        [-0.1644],\n",
            "        [-0.4047],\n",
            "        [-0.1130],\n",
            "        [-0.2324],\n",
            "        [-0.2008],\n",
            "        [-0.0645]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1839],\n",
            "        [-0.0171],\n",
            "        [ 0.1504],\n",
            "        [ 0.1863],\n",
            "        [ 0.1555],\n",
            "        [-0.0638],\n",
            "        [-0.3548],\n",
            "        [-0.1115],\n",
            "        [-0.2060],\n",
            "        [-0.2148],\n",
            "        [-0.0695],\n",
            "        [-0.0401]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0339],\n",
            "        [ 0.1447],\n",
            "        [ 0.1433],\n",
            "        [ 0.1028],\n",
            "        [-0.0489],\n",
            "        [-0.2834],\n",
            "        [-0.1144],\n",
            "        [-0.1714],\n",
            "        [-0.2066],\n",
            "        [-0.0551],\n",
            "        [-0.0274],\n",
            "        [ 0.0768]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1234],\n",
            "        [ 0.1068],\n",
            "        [ 0.0519],\n",
            "        [-0.0668],\n",
            "        [-0.2456],\n",
            "        [-0.0995],\n",
            "        [-0.1360],\n",
            "        [-0.1763],\n",
            "        [-0.0218],\n",
            "        [-0.0009],\n",
            "        [ 0.0819],\n",
            "        [ 0.3222]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0716],\n",
            "        [-0.0043],\n",
            "        [-0.0908],\n",
            "        [-0.2278],\n",
            "        [-0.0803],\n",
            "        [-0.0916],\n",
            "        [-0.1360],\n",
            "        [ 0.0058],\n",
            "        [-0.0058],\n",
            "        [ 0.0246],\n",
            "        [ 0.2168],\n",
            "        [ 0.3275]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0392],\n",
            "        [-0.1347],\n",
            "        [-0.2461],\n",
            "        [-0.0955],\n",
            "        [-0.0757],\n",
            "        [-0.0720],\n",
            "        [ 0.0846],\n",
            "        [ 0.0333],\n",
            "        [-0.0162],\n",
            "        [ 0.1262],\n",
            "        [ 0.2071],\n",
            "        [ 0.1338]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1633],\n",
            "        [-0.2669],\n",
            "        [-0.1312],\n",
            "        [-0.1060],\n",
            "        [-0.0620],\n",
            "        [ 0.1455],\n",
            "        [ 0.1201],\n",
            "        [ 0.0257],\n",
            "        [ 0.1255],\n",
            "        [ 0.1820],\n",
            "        [ 0.0689],\n",
            "        [-0.0861]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2869],\n",
            "        [-0.1335],\n",
            "        [-0.1302],\n",
            "        [-0.0956],\n",
            "        [ 0.1146],\n",
            "        [ 0.1524],\n",
            "        [ 0.1289],\n",
            "        [ 0.2147],\n",
            "        [ 0.2327],\n",
            "        [ 0.0466],\n",
            "        [-0.1796],\n",
            "        [-0.2022]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1488],\n",
            "        [-0.1065],\n",
            "        [-0.1212],\n",
            "        [ 0.0587],\n",
            "        [ 0.0934],\n",
            "        [ 0.1610],\n",
            "        [ 0.3320],\n",
            "        [ 0.3580],\n",
            "        [ 0.1060],\n",
            "        [-0.2453],\n",
            "        [-0.2825],\n",
            "        [-0.1148]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1285],\n",
            "        [-0.1277],\n",
            "        [ 0.0166],\n",
            "        [ 0.0474],\n",
            "        [ 0.1454],\n",
            "        [ 0.3886],\n",
            "        [ 0.4838],\n",
            "        [ 0.2225],\n",
            "        [-0.2717],\n",
            "        [-0.3524],\n",
            "        [-0.1157],\n",
            "        [-0.0825]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1513],\n",
            "        [ 0.0019],\n",
            "        [ 0.0082],\n",
            "        [ 0.0991],\n",
            "        [ 0.3630],\n",
            "        [ 0.5446],\n",
            "        [ 0.3870],\n",
            "        [-0.1774],\n",
            "        [-0.4312],\n",
            "        [-0.1136],\n",
            "        [-0.0949],\n",
            "        [-0.0414]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0202],\n",
            "        [-0.0028],\n",
            "        [ 0.0503],\n",
            "        [ 0.2922],\n",
            "        [ 0.5001],\n",
            "        [ 0.4927],\n",
            "        [ 0.0545],\n",
            "        [-0.4170],\n",
            "        [-0.1885],\n",
            "        [-0.0693],\n",
            "        [-0.0723],\n",
            "        [-0.0311]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0325],\n",
            "        [ 0.0131],\n",
            "        [ 0.2281],\n",
            "        [ 0.4339],\n",
            "        [ 0.5141],\n",
            "        [ 0.2494],\n",
            "        [-0.2657],\n",
            "        [-0.2861],\n",
            "        [-0.0209],\n",
            "        [-0.1015],\n",
            "        [-0.0522],\n",
            "        [ 0.1200]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0160],\n",
            "        [ 0.1864],\n",
            "        [ 0.3610],\n",
            "        [ 0.4515],\n",
            "        [ 0.3123],\n",
            "        [-0.0766],\n",
            "        [-0.2909],\n",
            "        [-0.0056],\n",
            "        [-0.0981],\n",
            "        [-0.0716],\n",
            "        [ 0.1083],\n",
            "        [ 0.1611]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1600],\n",
            "        [ 0.3104],\n",
            "        [ 0.3728],\n",
            "        [ 0.2713],\n",
            "        [ 0.0100],\n",
            "        [-0.2081],\n",
            "        [-0.0174],\n",
            "        [-0.0630],\n",
            "        [-0.0645],\n",
            "        [ 0.1321],\n",
            "        [ 0.1883],\n",
            "        [ 0.3409]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2762],\n",
            "        [ 0.2995],\n",
            "        [ 0.2277],\n",
            "        [ 0.0447],\n",
            "        [-0.1553],\n",
            "        [-0.0114],\n",
            "        [-0.0278],\n",
            "        [-0.0578],\n",
            "        [ 0.1506],\n",
            "        [ 0.1972],\n",
            "        [ 0.3242],\n",
            "        [ 0.6090]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2529],\n",
            "        [ 0.1539],\n",
            "        [ 0.0560],\n",
            "        [-0.0959],\n",
            "        [ 0.0118],\n",
            "        [ 0.0241],\n",
            "        [-0.0518],\n",
            "        [ 0.1390],\n",
            "        [ 0.1384],\n",
            "        [ 0.1963],\n",
            "        [ 0.4276],\n",
            "        [ 0.5498]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1021],\n",
            "        [-0.0112],\n",
            "        [-0.0883],\n",
            "        [ 0.0361],\n",
            "        [ 0.0753],\n",
            "        [ 0.0192],\n",
            "        [ 0.1958],\n",
            "        [ 0.1229],\n",
            "        [ 0.0726],\n",
            "        [ 0.2341],\n",
            "        [ 0.3333],\n",
            "        [ 0.3006]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0540],\n",
            "        [-0.1384],\n",
            "        [-0.0029],\n",
            "        [ 0.0564],\n",
            "        [ 0.0685],\n",
            "        [ 0.3000],\n",
            "        [ 0.2192],\n",
            "        [ 0.0880],\n",
            "        [ 0.1992],\n",
            "        [ 0.2814],\n",
            "        [ 0.2111],\n",
            "        [ 0.0641]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1692],\n",
            "        [-0.0321],\n",
            "        [ 0.0118],\n",
            "        [ 0.0361],\n",
            "        [ 0.2996],\n",
            "        [ 0.2949],\n",
            "        [ 0.2148],\n",
            "        [ 0.3012],\n",
            "        [ 0.3324],\n",
            "        [ 0.1715],\n",
            "        [-0.0661],\n",
            "        [-0.1158]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0534],\n",
            "        [ 0.0046],\n",
            "        [-0.0067],\n",
            "        [ 0.2333],\n",
            "        [ 0.2624],\n",
            "        [ 0.2987],\n",
            "        [ 0.4545],\n",
            "        [ 0.4600],\n",
            "        [ 0.2052],\n",
            "        [-0.1572],\n",
            "        [-0.2084],\n",
            "        [ 0.0414]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0240],\n",
            "        [-0.0374],\n",
            "        [ 0.1733],\n",
            "        [ 0.2125],\n",
            "        [ 0.3144],\n",
            "        [ 0.5598],\n",
            "        [ 0.6206],\n",
            "        [ 0.3192],\n",
            "        [-0.2260],\n",
            "        [-0.3027],\n",
            "        [ 0.0393],\n",
            "        [ 0.0776]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0697],\n",
            "        [ 0.1315],\n",
            "        [ 0.1552],\n",
            "        [ 0.2705],\n",
            "        [ 0.5653],\n",
            "        [ 0.7297],\n",
            "        [ 0.5122],\n",
            "        [-0.1758],\n",
            "        [-0.4102],\n",
            "        [ 0.0437],\n",
            "        [ 0.0540],\n",
            "        [ 0.0795]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1055],\n",
            "        [ 0.1202],\n",
            "        [ 0.2038],\n",
            "        [ 0.4819],\n",
            "        [ 0.6974],\n",
            "        [ 0.6578],\n",
            "        [ 0.0677],\n",
            "        [-0.4302],\n",
            "        [-0.0406],\n",
            "        [ 0.0779],\n",
            "        [ 0.0577],\n",
            "        [ 0.1073]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0799],\n",
            "        [ 0.1386],\n",
            "        [ 0.4020],\n",
            "        [ 0.6349],\n",
            "        [ 0.7191],\n",
            "        [ 0.3008],\n",
            "        [-0.3336],\n",
            "        [-0.1582],\n",
            "        [ 0.1045],\n",
            "        [ 0.0260],\n",
            "        [ 0.0794],\n",
            "        [ 0.2131]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1003],\n",
            "        [ 0.3316],\n",
            "        [ 0.5376],\n",
            "        [ 0.6536],\n",
            "        [ 0.4069],\n",
            "        [-0.1197],\n",
            "        [-0.2027],\n",
            "        [ 0.1146],\n",
            "        [ 0.0266],\n",
            "        [ 0.0705],\n",
            "        [ 0.2088],\n",
            "        [ 0.2587]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2985],\n",
            "        [ 0.4598],\n",
            "        [ 0.5574],\n",
            "        [ 0.3835],\n",
            "        [ 0.0078],\n",
            "        [-0.1354],\n",
            "        [ 0.1028],\n",
            "        [ 0.0592],\n",
            "        [ 0.0840],\n",
            "        [ 0.2310],\n",
            "        [ 0.2998],\n",
            "        [ 0.5103]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4146],\n",
            "        [ 0.4746],\n",
            "        [ 0.3759],\n",
            "        [ 0.1038],\n",
            "        [-0.1322],\n",
            "        [ 0.0772],\n",
            "        [ 0.0560],\n",
            "        [ 0.0487],\n",
            "        [ 0.2101],\n",
            "        [ 0.2729],\n",
            "        [ 0.4787],\n",
            "        [ 0.8613]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4154],\n",
            "        [ 0.3035],\n",
            "        [ 0.1840],\n",
            "        [-0.0313],\n",
            "        [ 0.0570],\n",
            "        [ 0.0870],\n",
            "        [-0.0018],\n",
            "        [ 0.1588],\n",
            "        [ 0.1719],\n",
            "        [ 0.3033],\n",
            "        [ 0.6200],\n",
            "        [ 0.8649]], grad_fn=<AddmmBackward>)\n",
            "tensor([[0.2348],\n",
            "        [0.1126],\n",
            "        [0.0338],\n",
            "        [0.1317],\n",
            "        [0.1542],\n",
            "        [0.0505],\n",
            "        [0.1644],\n",
            "        [0.0851],\n",
            "        [0.0974],\n",
            "        [0.2988],\n",
            "        [0.4440],\n",
            "        [0.4660]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0587],\n",
            "        [-0.0372],\n",
            "        [ 0.1013],\n",
            "        [ 0.1532],\n",
            "        [ 0.1187],\n",
            "        [ 0.2697],\n",
            "        [ 0.1550],\n",
            "        [ 0.0932],\n",
            "        [ 0.2512],\n",
            "        [ 0.3457],\n",
            "        [ 0.3064],\n",
            "        [ 0.0869]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0768],\n",
            "        [ 0.0463],\n",
            "        [ 0.0922],\n",
            "        [ 0.0926],\n",
            "        [ 0.2955],\n",
            "        [ 0.2355],\n",
            "        [ 0.1943],\n",
            "        [ 0.3466],\n",
            "        [ 0.3977],\n",
            "        [ 0.2577],\n",
            "        [-0.0735],\n",
            "        [-0.1624]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0184],\n",
            "        [ 0.0598],\n",
            "        [ 0.0372],\n",
            "        [ 0.2322],\n",
            "        [ 0.2210],\n",
            "        [ 0.2672],\n",
            "        [ 0.4612],\n",
            "        [ 0.5240],\n",
            "        [ 0.3243],\n",
            "        [-0.1603],\n",
            "        [-0.2802],\n",
            "        [ 0.0332]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0282],\n",
            "        [-0.0090],\n",
            "        [ 0.1677],\n",
            "        [ 0.1762],\n",
            "        [ 0.2851],\n",
            "        [ 0.5417],\n",
            "        [ 0.6617],\n",
            "        [ 0.4557],\n",
            "        [-0.2104],\n",
            "        [-0.3947],\n",
            "        [ 0.0404],\n",
            "        [ 0.0557]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0416],\n",
            "        [ 0.1168],\n",
            "        [ 0.1162],\n",
            "        [ 0.2414],\n",
            "        [ 0.5374],\n",
            "        [ 0.7454],\n",
            "        [ 0.6329],\n",
            "        [-0.1344],\n",
            "        [-0.4829],\n",
            "        [ 0.0392],\n",
            "        [ 0.0412],\n",
            "        [ 0.0406]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0908],\n",
            "        [ 0.0785],\n",
            "        [ 0.1766],\n",
            "        [ 0.4548],\n",
            "        [ 0.6997],\n",
            "        [ 0.7356],\n",
            "        [ 0.0864],\n",
            "        [-0.4528],\n",
            "        [-0.0489],\n",
            "        [ 0.0685],\n",
            "        [ 0.0284],\n",
            "        [ 0.0689]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0486],\n",
            "        [ 0.1190],\n",
            "        [ 0.3736],\n",
            "        [ 0.6195],\n",
            "        [ 0.7533],\n",
            "        [ 0.2909],\n",
            "        [-0.3009],\n",
            "        [-0.1564],\n",
            "        [ 0.1022],\n",
            "        [ 0.0175],\n",
            "        [ 0.0517],\n",
            "        [ 0.2222]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0933],\n",
            "        [ 0.3158],\n",
            "        [ 0.5269],\n",
            "        [ 0.6669],\n",
            "        [ 0.3614],\n",
            "        [-0.0923],\n",
            "        [-0.1789],\n",
            "        [ 0.1044],\n",
            "        [ 0.0365],\n",
            "        [ 0.0597],\n",
            "        [ 0.2337],\n",
            "        [ 0.2806]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2966],\n",
            "        [ 0.4614],\n",
            "        [ 0.5760],\n",
            "        [ 0.3378],\n",
            "        [ 0.0217],\n",
            "        [-0.1102],\n",
            "        [ 0.0916],\n",
            "        [ 0.0819],\n",
            "        [ 0.0935],\n",
            "        [ 0.2764],\n",
            "        [ 0.3384],\n",
            "        [ 0.5414]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4398],\n",
            "        [ 0.5042],\n",
            "        [ 0.3260],\n",
            "        [ 0.0989],\n",
            "        [-0.0955],\n",
            "        [ 0.0784],\n",
            "        [ 0.0985],\n",
            "        [ 0.0902],\n",
            "        [ 0.2879],\n",
            "        [ 0.3510],\n",
            "        [ 0.5533],\n",
            "        [ 0.8211]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4754],\n",
            "        [ 0.2657],\n",
            "        [ 0.1783],\n",
            "        [-0.0359],\n",
            "        [ 0.0508],\n",
            "        [ 0.1292],\n",
            "        [ 0.0574],\n",
            "        [ 0.2652],\n",
            "        [ 0.2910],\n",
            "        [ 0.4335],\n",
            "        [ 0.6404],\n",
            "        [ 0.8616]], grad_fn=<AddmmBackward>)\n",
            "tensor([[0.2182],\n",
            "        [0.1241],\n",
            "        [0.0320],\n",
            "        [0.1144],\n",
            "        [0.1986],\n",
            "        [0.1121],\n",
            "        [0.2807],\n",
            "        [0.2006],\n",
            "        [0.1949],\n",
            "        [0.2912],\n",
            "        [0.4477],\n",
            "        [0.4982]], grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0910],\n",
            "        [-0.0250],\n",
            "        [ 0.0970],\n",
            "        [ 0.1983],\n",
            "        [ 0.1717],\n",
            "        [ 0.3882],\n",
            "        [ 0.2876],\n",
            "        [ 0.2114],\n",
            "        [ 0.2481],\n",
            "        [ 0.3868],\n",
            "        [ 0.4117],\n",
            "        [ 0.3143]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0568],\n",
            "        [ 0.0505],\n",
            "        [ 0.1506],\n",
            "        [ 0.1612],\n",
            "        [ 0.4307],\n",
            "        [ 0.3909],\n",
            "        [ 0.3354],\n",
            "        [ 0.3373],\n",
            "        [ 0.4224],\n",
            "        [ 0.3627],\n",
            "        [ 0.1874],\n",
            "        [ 0.1342]], grad_fn=<AddmmBackward>)\n",
            "tensor([[0.0293],\n",
            "        [0.1249],\n",
            "        [0.1188],\n",
            "        [0.3788],\n",
            "        [0.3966],\n",
            "        [0.4435],\n",
            "        [0.4907],\n",
            "        [0.5443],\n",
            "        [0.3887],\n",
            "        [0.1162],\n",
            "        [0.0408],\n",
            "        [0.2577]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7027],\n",
            "        [-0.7111],\n",
            "        [-0.7026],\n",
            "        [-0.7620],\n",
            "        [-0.8083],\n",
            "        [-0.7446],\n",
            "        [-0.5814],\n",
            "        [-0.4262],\n",
            "        [-0.5146],\n",
            "        [-0.7027],\n",
            "        [-0.7514],\n",
            "        [-0.7553]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6861],\n",
            "        [-0.6666],\n",
            "        [-0.7237],\n",
            "        [-0.7822],\n",
            "        [-0.7745],\n",
            "        [-0.7203],\n",
            "        [-0.5875],\n",
            "        [-0.4782],\n",
            "        [-0.6023],\n",
            "        [-0.7244],\n",
            "        [-0.7002],\n",
            "        [-0.7896]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6440],\n",
            "        [-0.6857],\n",
            "        [-0.7589],\n",
            "        [-0.7450],\n",
            "        [-0.7575],\n",
            "        [-0.7199],\n",
            "        [-0.6315],\n",
            "        [-0.5646],\n",
            "        [-0.6896],\n",
            "        [-0.6334],\n",
            "        [-0.7855],\n",
            "        [-0.7461]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6589],\n",
            "        [-0.7267],\n",
            "        [-0.7187],\n",
            "        [-0.7287],\n",
            "        [-0.7574],\n",
            "        [-0.7569],\n",
            "        [-0.7016],\n",
            "        [-0.6757],\n",
            "        [-0.6295],\n",
            "        [-0.7350],\n",
            "        [-0.7725],\n",
            "        [-0.7445]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6921],\n",
            "        [-0.6896],\n",
            "        [-0.6900],\n",
            "        [-0.7403],\n",
            "        [-0.7977],\n",
            "        [-0.8338],\n",
            "        [-0.8069],\n",
            "        [-0.6613],\n",
            "        [-0.7138],\n",
            "        [-0.7495],\n",
            "        [-0.7427],\n",
            "        [-0.7744]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6523],\n",
            "        [-0.6547],\n",
            "        [-0.7061],\n",
            "        [-0.7856],\n",
            "        [-0.8782],\n",
            "        [-0.9357],\n",
            "        [-0.8183],\n",
            "        [-0.7630],\n",
            "        [-0.6777],\n",
            "        [-0.6726],\n",
            "        [-0.7435],\n",
            "        [-0.7947]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6144],\n",
            "        [-0.6661],\n",
            "        [-0.7627],\n",
            "        [-0.8571],\n",
            "        [-0.9665],\n",
            "        [-0.9381],\n",
            "        [-0.9116],\n",
            "        [-0.7273],\n",
            "        [-0.5786],\n",
            "        [-0.6478],\n",
            "        [-0.7758],\n",
            "        [-0.7092]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6202],\n",
            "        [-0.7243],\n",
            "        [-0.8395],\n",
            "        [-0.9324],\n",
            "        [-0.9635],\n",
            "        [-1.0087],\n",
            "        [-0.8807],\n",
            "        [-0.6509],\n",
            "        [-0.5606],\n",
            "        [-0.6993],\n",
            "        [-0.6665],\n",
            "        [-0.6758]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6679],\n",
            "        [-0.8055],\n",
            "        [-0.9102],\n",
            "        [-0.9163],\n",
            "        [-1.0238],\n",
            "        [-0.9832],\n",
            "        [-0.8289],\n",
            "        [-0.6348],\n",
            "        [-0.6024],\n",
            "        [-0.5970],\n",
            "        [-0.6287],\n",
            "        [-0.7059]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7336],\n",
            "        [-0.8824],\n",
            "        [-0.8723],\n",
            "        [-0.9678],\n",
            "        [-1.0003],\n",
            "        [-0.9584],\n",
            "        [-0.8328],\n",
            "        [-0.6554],\n",
            "        [-0.4996],\n",
            "        [-0.5457],\n",
            "        [-0.7055],\n",
            "        [-0.7534]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7940],\n",
            "        [-0.8504],\n",
            "        [-0.9035],\n",
            "        [-0.9522],\n",
            "        [-0.9829],\n",
            "        [-0.9923],\n",
            "        [-0.8696],\n",
            "        [-0.5453],\n",
            "        [-0.4461],\n",
            "        [-0.6354],\n",
            "        [-0.7782],\n",
            "        [-0.8773]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7535],\n",
            "        [-0.8766],\n",
            "        [-0.8812],\n",
            "        [-0.9231],\n",
            "        [-1.0172],\n",
            "        [-1.0405],\n",
            "        [-0.7976],\n",
            "        [-0.5045],\n",
            "        [-0.5036],\n",
            "        [-0.7196],\n",
            "        [-0.8818],\n",
            "        [-0.9476]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7702],\n",
            "        [-0.8477],\n",
            "        [-0.8379],\n",
            "        [-0.9561],\n",
            "        [-1.0526],\n",
            "        [-0.9730],\n",
            "        [-0.7472],\n",
            "        [-0.5280],\n",
            "        [-0.5580],\n",
            "        [-0.8236],\n",
            "        [-0.8962],\n",
            "        [-0.8693]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7356],\n",
            "        [-0.7939],\n",
            "        [-0.8695],\n",
            "        [-0.9868],\n",
            "        [-0.9899],\n",
            "        [-0.9299],\n",
            "        [-0.7627],\n",
            "        [-0.5620],\n",
            "        [-0.6747],\n",
            "        [-0.8452],\n",
            "        [-0.7862],\n",
            "        [-0.9033]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6838],\n",
            "        [-0.8164],\n",
            "        [-0.9118],\n",
            "        [-0.9059],\n",
            "        [-0.9387],\n",
            "        [-0.9129],\n",
            "        [-0.7770],\n",
            "        [-0.6674],\n",
            "        [-0.7827],\n",
            "        [-0.6836],\n",
            "        [-0.8845],\n",
            "        [-0.8781]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7042],\n",
            "        [-0.8551],\n",
            "        [-0.8158],\n",
            "        [-0.8433],\n",
            "        [-0.9022],\n",
            "        [-0.9010],\n",
            "        [-0.8318],\n",
            "        [-0.7703],\n",
            "        [-0.6398],\n",
            "        [-0.8035],\n",
            "        [-0.8740],\n",
            "        [-0.8089]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7380],\n",
            "        [-0.7576],\n",
            "        [-0.7306],\n",
            "        [-0.8211],\n",
            "        [-0.8940],\n",
            "        [-0.9654],\n",
            "        [-0.9200],\n",
            "        [-0.6685],\n",
            "        [-0.7196],\n",
            "        [-0.8465],\n",
            "        [-0.7546],\n",
            "        [-0.8305]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6474],\n",
            "        [-0.6557],\n",
            "        [-0.7132],\n",
            "        [-0.8158],\n",
            "        [-0.9555],\n",
            "        [-1.0408],\n",
            "        [-0.8586],\n",
            "        [-0.7562],\n",
            "        [-0.6953],\n",
            "        [-0.5830],\n",
            "        [-0.7041],\n",
            "        [-0.6820]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5678],\n",
            "        [-0.6393],\n",
            "        [-0.7440],\n",
            "        [-0.8837],\n",
            "        [-1.0211],\n",
            "        [-0.9616],\n",
            "        [-0.9094],\n",
            "        [-0.7138],\n",
            "        [-0.3981],\n",
            "        [-0.5105],\n",
            "        [-0.6414],\n",
            "        [-0.6394]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5643],\n",
            "        [-0.6789],\n",
            "        [-0.8323],\n",
            "        [-0.9475],\n",
            "        [-0.9454],\n",
            "        [-0.9758],\n",
            "        [-0.8472],\n",
            "        [-0.4688],\n",
            "        [-0.3477],\n",
            "        [-0.4996],\n",
            "        [-0.5824],\n",
            "        [-0.5662]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6044],\n",
            "        [-0.7747],\n",
            "        [-0.9000],\n",
            "        [-0.8620],\n",
            "        [-0.9551],\n",
            "        [-0.9163],\n",
            "        [-0.6555],\n",
            "        [-0.4162],\n",
            "        [-0.2719],\n",
            "        [-0.5269],\n",
            "        [-0.4972],\n",
            "        [-0.6061]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6915],\n",
            "        [-0.8528],\n",
            "        [-0.7929],\n",
            "        [-0.8692],\n",
            "        [-0.9026],\n",
            "        [-0.7771],\n",
            "        [-0.6313],\n",
            "        [-0.2672],\n",
            "        [-0.3273],\n",
            "        [-0.4501],\n",
            "        [-0.5607],\n",
            "        [-0.6578]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7579],\n",
            "        [-0.7535],\n",
            "        [-0.7739],\n",
            "        [-0.8368],\n",
            "        [-0.7862],\n",
            "        [-0.7998],\n",
            "        [-0.5086],\n",
            "        [-0.2575],\n",
            "        [-0.2741],\n",
            "        [-0.4920],\n",
            "        [-0.6502],\n",
            "        [-0.7260]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6657],\n",
            "        [-0.7260],\n",
            "        [-0.7509],\n",
            "        [-0.7211],\n",
            "        [-0.8207],\n",
            "        [-0.7131],\n",
            "        [-0.5145],\n",
            "        [-0.1807],\n",
            "        [-0.3007],\n",
            "        [-0.6041],\n",
            "        [-0.7181],\n",
            "        [-0.7516]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6477],\n",
            "        [-0.7041],\n",
            "        [-0.6419],\n",
            "        [-0.7659],\n",
            "        [-0.7418],\n",
            "        [-0.6941],\n",
            "        [-0.4078],\n",
            "        [-0.2203],\n",
            "        [-0.4038],\n",
            "        [-0.6901],\n",
            "        [-0.6989],\n",
            "        [-0.6916]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6299],\n",
            "        [-0.5924],\n",
            "        [-0.6968],\n",
            "        [-0.7039],\n",
            "        [-0.7283],\n",
            "        [-0.5951],\n",
            "        [-0.4271],\n",
            "        [-0.2882],\n",
            "        [-0.5190],\n",
            "        [-0.6777],\n",
            "        [-0.6093],\n",
            "        [-0.7003]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5286],\n",
            "        [-0.6401],\n",
            "        [-0.6542],\n",
            "        [-0.6806],\n",
            "        [-0.6397],\n",
            "        [-0.5916],\n",
            "        [-0.4647],\n",
            "        [-0.4108],\n",
            "        [-0.5976],\n",
            "        [-0.5191],\n",
            "        [-0.6725],\n",
            "        [-0.6522]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5819],\n",
            "        [-0.6087],\n",
            "        [-0.6320],\n",
            "        [-0.6036],\n",
            "        [-0.6243],\n",
            "        [-0.5949],\n",
            "        [-0.5335],\n",
            "        [-0.5301],\n",
            "        [-0.4885],\n",
            "        [-0.5958],\n",
            "        [-0.6653],\n",
            "        [-0.6178]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5492],\n",
            "        [-0.5815],\n",
            "        [-0.5479],\n",
            "        [-0.5928],\n",
            "        [-0.6401],\n",
            "        [-0.6721],\n",
            "        [-0.6440],\n",
            "        [-0.4811],\n",
            "        [-0.5282],\n",
            "        [-0.6164],\n",
            "        [-0.5961],\n",
            "        [-0.6440]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5274],\n",
            "        [-0.4977],\n",
            "        [-0.5434],\n",
            "        [-0.6220],\n",
            "        [-0.7124],\n",
            "        [-0.7575],\n",
            "        [-0.6104],\n",
            "        [-0.5407],\n",
            "        [-0.4911],\n",
            "        [-0.4734],\n",
            "        [-0.5726],\n",
            "        [-0.5851]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4505],\n",
            "        [-0.4882],\n",
            "        [-0.5896],\n",
            "        [-0.6922],\n",
            "        [-0.7846],\n",
            "        [-0.7160],\n",
            "        [-0.6645],\n",
            "        [-0.4978],\n",
            "        [-0.3190],\n",
            "        [-0.4063],\n",
            "        [-0.5443],\n",
            "        [-0.4300]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4497],\n",
            "        [-0.5439],\n",
            "        [-0.6746],\n",
            "        [-0.7585],\n",
            "        [-0.7365],\n",
            "        [-0.7364],\n",
            "        [-0.6041],\n",
            "        [-0.3571],\n",
            "        [-0.2736],\n",
            "        [-0.4280],\n",
            "        [-0.3706],\n",
            "        [-0.4469]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5026],\n",
            "        [-0.6325],\n",
            "        [-0.7400],\n",
            "        [-0.6996],\n",
            "        [-0.7501],\n",
            "        [-0.6798],\n",
            "        [-0.4977],\n",
            "        [-0.3085],\n",
            "        [-0.2592],\n",
            "        [-0.2902],\n",
            "        [-0.3859],\n",
            "        [-0.4600]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5814],\n",
            "        [-0.7022],\n",
            "        [-0.6651],\n",
            "        [-0.7061],\n",
            "        [-0.7011],\n",
            "        [-0.6104],\n",
            "        [-0.4784],\n",
            "        [-0.2442],\n",
            "        [-0.1285],\n",
            "        [-0.2965],\n",
            "        [-0.4448],\n",
            "        [-0.5942]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6387],\n",
            "        [-0.6294],\n",
            "        [-0.6490],\n",
            "        [-0.6664],\n",
            "        [-0.6430],\n",
            "        [-0.6261],\n",
            "        [-0.4301],\n",
            "        [-0.0922],\n",
            "        [-0.1308],\n",
            "        [-0.3404],\n",
            "        [-0.6079],\n",
            "        [-0.6192]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5678],\n",
            "        [-0.6059],\n",
            "        [-0.6122],\n",
            "        [-0.6091],\n",
            "        [-0.6688],\n",
            "        [-0.5991],\n",
            "        [-0.3121],\n",
            "        [-0.0915],\n",
            "        [-0.0875],\n",
            "        [-0.5115],\n",
            "        [-0.6410],\n",
            "        [-0.6026]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5505],\n",
            "        [-0.5710],\n",
            "        [-0.5623],\n",
            "        [-0.6427],\n",
            "        [-0.6415],\n",
            "        [-0.4757],\n",
            "        [-0.2836],\n",
            "        [-0.0238],\n",
            "        [-0.2669],\n",
            "        [-0.5969],\n",
            "        [-0.5522],\n",
            "        [-0.5545]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5190],\n",
            "        [-0.5194],\n",
            "        [-0.6062],\n",
            "        [-0.6222],\n",
            "        [-0.5272],\n",
            "        [-0.4379],\n",
            "        [-0.1986],\n",
            "        [-0.1691],\n",
            "        [-0.3972],\n",
            "        [-0.5403],\n",
            "        [-0.4753],\n",
            "        [-0.5935]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4729],\n",
            "        [-0.5626],\n",
            "        [-0.5979],\n",
            "        [-0.5021],\n",
            "        [-0.4881],\n",
            "        [-0.3429],\n",
            "        [-0.2983],\n",
            "        [-0.2764],\n",
            "        [-0.5100],\n",
            "        [-0.3829],\n",
            "        [-0.5885],\n",
            "        [-0.5718]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5155],\n",
            "        [-0.5578],\n",
            "        [-0.4658],\n",
            "        [-0.4641],\n",
            "        [-0.3912],\n",
            "        [-0.4149],\n",
            "        [-0.3498],\n",
            "        [-0.4676],\n",
            "        [-0.3756],\n",
            "        [-0.5275],\n",
            "        [-0.5819],\n",
            "        [-0.4406]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5074],\n",
            "        [-0.4201],\n",
            "        [-0.4151],\n",
            "        [-0.3816],\n",
            "        [-0.4694],\n",
            "        [-0.4647],\n",
            "        [-0.5244],\n",
            "        [-0.4054],\n",
            "        [-0.4770],\n",
            "        [-0.5662],\n",
            "        [-0.4099],\n",
            "        [-0.4058]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3806],\n",
            "        [-0.3613],\n",
            "        [-0.3495],\n",
            "        [-0.4718],\n",
            "        [-0.5230],\n",
            "        [-0.6040],\n",
            "        [-0.4859],\n",
            "        [-0.4933],\n",
            "        [-0.4995],\n",
            "        [-0.3239],\n",
            "        [-0.3116],\n",
            "        [-0.2969]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3379],\n",
            "        [-0.3123],\n",
            "        [-0.4649],\n",
            "        [-0.5336],\n",
            "        [-0.6331],\n",
            "        [-0.5456],\n",
            "        [-0.5432],\n",
            "        [-0.4820],\n",
            "        [-0.2388],\n",
            "        [-0.2062],\n",
            "        [-0.2815],\n",
            "        [-0.3310]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2949],\n",
            "        [-0.4302],\n",
            "        [-0.5394],\n",
            "        [-0.6303],\n",
            "        [-0.5733],\n",
            "        [-0.5864],\n",
            "        [-0.5193],\n",
            "        [-0.2344],\n",
            "        [-0.1285],\n",
            "        [-0.2170],\n",
            "        [-0.3287],\n",
            "        [-0.2816]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4139],\n",
            "        [-0.5128],\n",
            "        [-0.6304],\n",
            "        [-0.5667],\n",
            "        [-0.6052],\n",
            "        [-0.5581],\n",
            "        [-0.2946],\n",
            "        [-0.1303],\n",
            "        [-0.1299],\n",
            "        [-0.2723],\n",
            "        [-0.2452],\n",
            "        [-0.3259]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4798],\n",
            "        [-0.5934],\n",
            "        [-0.5540],\n",
            "        [-0.5834],\n",
            "        [-0.5884],\n",
            "        [-0.3909],\n",
            "        [-0.2489],\n",
            "        [-0.0835],\n",
            "        [-0.1292],\n",
            "        [-0.1708],\n",
            "        [-0.2861],\n",
            "        [-0.4916]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5497],\n",
            "        [-0.5159],\n",
            "        [-0.5518],\n",
            "        [-0.5736],\n",
            "        [-0.4385],\n",
            "        [-0.3775],\n",
            "        [-0.1982],\n",
            "        [-0.0337],\n",
            "        [-0.0718],\n",
            "        [-0.1854],\n",
            "        [-0.4840],\n",
            "        [-0.6076]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4717],\n",
            "        [-0.5030],\n",
            "        [-0.5461],\n",
            "        [-0.4223],\n",
            "        [-0.4390],\n",
            "        [-0.3449],\n",
            "        [-0.1432],\n",
            "        [ 0.0277],\n",
            "        [-0.0725],\n",
            "        [-0.4138],\n",
            "        [-0.6083],\n",
            "        [-0.6337]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4654],\n",
            "        [-0.5030],\n",
            "        [-0.3932],\n",
            "        [-0.4265],\n",
            "        [-0.4024],\n",
            "        [-0.2695],\n",
            "        [-0.0523],\n",
            "        [ 0.0162],\n",
            "        [-0.3241],\n",
            "        [-0.5595],\n",
            "        [-0.6163],\n",
            "        [-0.5325]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4664],\n",
            "        [-0.3507],\n",
            "        [-0.3926],\n",
            "        [-0.4074],\n",
            "        [-0.3352],\n",
            "        [-0.1830],\n",
            "        [-0.0412],\n",
            "        [-0.2068],\n",
            "        [-0.4857],\n",
            "        [-0.5766],\n",
            "        [-0.5079],\n",
            "        [-0.5523]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3228],\n",
            "        [-0.3422],\n",
            "        [-0.3956],\n",
            "        [-0.3457],\n",
            "        [-0.2618],\n",
            "        [-0.1619],\n",
            "        [-0.2145],\n",
            "        [-0.3613],\n",
            "        [-0.5807],\n",
            "        [-0.4248],\n",
            "        [-0.5610],\n",
            "        [-0.5769]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3264],\n",
            "        [-0.3645],\n",
            "        [-0.3440],\n",
            "        [-0.2719],\n",
            "        [-0.2143],\n",
            "        [-0.2624],\n",
            "        [-0.3345],\n",
            "        [-0.5551],\n",
            "        [-0.4072],\n",
            "        [-0.5281],\n",
            "        [-0.5856],\n",
            "        [-0.4356]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3484],\n",
            "        [-0.3141],\n",
            "        [-0.2653],\n",
            "        [-0.2280],\n",
            "        [-0.3090],\n",
            "        [-0.3661],\n",
            "        [-0.5420],\n",
            "        [-0.4329],\n",
            "        [-0.4897],\n",
            "        [-0.6017],\n",
            "        [-0.4168],\n",
            "        [-0.4510]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2976],\n",
            "        [-0.2306],\n",
            "        [-0.2203],\n",
            "        [-0.3278],\n",
            "        [-0.4085],\n",
            "        [-0.5594],\n",
            "        [-0.4664],\n",
            "        [-0.4952],\n",
            "        [-0.5888],\n",
            "        [-0.3897],\n",
            "        [-0.4051],\n",
            "        [-0.2495]], grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2223],\n",
            "        [-0.1937],\n",
            "        [-0.3343],\n",
            "        [-0.4295],\n",
            "        [-0.5780],\n",
            "        [-0.4969],\n",
            "        [-0.5196],\n",
            "        [-0.5717],\n",
            "        [-0.3460],\n",
            "        [-0.3380],\n",
            "        [-0.2081],\n",
            "        [-0.1036]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-795feb4f6556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                         torch.zeros(1, 1, model.hidden_layer_size))\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msingle_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-89414b46bd39>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_cell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhDN72zKmiHm",
        "colab_type": "code",
        "outputId": "2bf47a88-20b6-4b15-d146-7370cfe3d02e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "for seq, labels in train_inout_seq[:2]:\n",
        "  # print (len(seq))\n",
        "  # print (seq.size())\n",
        "  print(seq)\n",
        "  seq.view(len(seq) ,1, -1)\n",
        "  print(seq)\n",
        "  print (seq.size())\n",
        "  print (seq.type)\n",
        "\n",
        "\n",
        "# y = torch.tensor([[[[-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066,\n",
        "#         -0.8593, -0.9341, -1.0000, -0.9385]]]])\n",
        "# print(y)\n",
        "# print(y.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "torch.Size([12])\n",
            "tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066,\n",
            "        -0.8593, -0.9341, -1.0000, -0.9385])\n",
            "tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066,\n",
            "        -0.8593, -0.9341, -1.0000, -0.9385])\n",
            "torch.Size([12])\n",
            "<built-in method type of Tensor object at 0x7f1edbe0fb40>\n",
            "12\n",
            "torch.Size([12])\n",
            "tensor([-0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593,\n",
            "        -0.9341, -1.0000, -0.9385, -0.9516])\n",
            "tensor([-0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593,\n",
            "        -0.9341, -1.0000, -0.9385, -0.9516])\n",
            "torch.Size([12])\n",
            "<built-in method type of Tensor object at 0x7f1edbe0fbd0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57PI4HixwAzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM2(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
        "\n",
        "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
        "\n",
        "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
        "                            torch.zeros(1,1,self.hidden_layer_size))\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
        "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
        "        print(predictions[-1])\n",
        "        print(predictions)\n",
        "        return predictions[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biRH9LN8wGEc",
        "colab_type": "code",
        "outputId": "289abf2d-220e-409c-b743-27900db25eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "for seq, labels in train_inout_seq[:1]:\n",
        "  print(seq)\n",
        "  model = LSTM2()\n",
        "  model(seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066,\n",
            "        -0.8593, -0.9341, -1.0000, -0.9385])\n",
            "tensor([-0.1019], grad_fn=<SelectBackward>)\n",
            "tensor([[-0.0791],\n",
            "        [-0.0897],\n",
            "        [-0.0942],\n",
            "        [-0.0968],\n",
            "        [-0.0987],\n",
            "        [-0.0991],\n",
            "        [-0.0988],\n",
            "        [-0.0988],\n",
            "        [-0.0995],\n",
            "        [-0.1007],\n",
            "        [-0.1020],\n",
            "        [-0.1019]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjH5cpPvJPTB",
        "colab_type": "code",
        "outputId": "baa9081a-33a4-44f8-d108-8d9ce1444d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Lọc 12 giá trị cuối từ tập train\n",
        "\n",
        "fut_pred = 12\n",
        "\n",
        "test_inputs = train_data_normalized[-train_window:].tolist()\n",
        "print(test_inputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.12527473270893097, 0.04615384712815285, 0.3274725377559662, 0.2835164964199066, 0.3890109956264496, 0.6175824403762817, 0.9516483545303345, 1.0, 0.5780220031738281, 0.33186814188957214, 0.13406594097614288, 0.32307693362236023]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzZ5lI2ZJR8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Trong vòng lặp for sẽ dùng 12 giá trị ở trên để dự đoán giá trị thứ 133\n",
        "#Giá trị dự đoán sẽ được thêm vào ds test_input\n",
        "#Trong lần lặp 2, 1 lần nữa 12 giá trị cuối sẽ được sử dụng làm đầu vào và đưa ra 1 dự đoán mới, và lại đưa vào ds test_input\n",
        "#Cuối vòng lặp test_input chứa 24 giá trị, 12 giá trị cuối cùng chính là giá trị dự đoán.\n",
        "model.eval()\n",
        "\n",
        "for i in range(fut_pred):\n",
        "    seq = torch.FloatTensor(test_inputs[-train_window:])\n",
        "    with torch.no_grad():\n",
        "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
        "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
        "        test_inputs.append(model(seq).item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFEt7fdRJbOU",
        "colab_type": "code",
        "outputId": "55d6e86d-8b2c-4a3a-cf7b-bf76be372754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "#Do đã chuẩn hóa dữ liệu để train, nên các giá trị dự đoán cũng chuẩn hóa\n",
        "test_inputs[fut_pred:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3997810184955597,\n",
              " 0.8084654808044434,\n",
              " 1.0614644289016724,\n",
              " 1.2469247579574585,\n",
              " 1.3791301250457764,\n",
              " 1.4569858312606812,\n",
              " 1.4912620782852173,\n",
              " 1.5000951290130615,\n",
              " 1.4961559772491455,\n",
              " 1.477561116218567,\n",
              " 1.4433006048202515,\n",
              " 1.404617428779602]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbiWTMYAJd6a",
        "colab_type": "code",
        "outputId": "d216f4bf-1f74-47db-fd31-b8043e31d97d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "#Chuyển các giá trị đã chuẩn hóa về thực tế\n",
        "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:] ).reshape(-1, 1))\n",
        "print(actual_predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[422.45018171]\n",
            " [515.42589688]\n",
            " [572.98315758]\n",
            " [615.17538244]\n",
            " [645.25210345]\n",
            " [662.96427661]\n",
            " [670.76212281]\n",
            " [672.77164185]\n",
            " [671.87548482]\n",
            " [667.64515394]\n",
            " [659.8508876 ]\n",
            " [651.05046505]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_Ksmn0IJlza",
        "colab_type": "code",
        "outputId": "2f140b87-788a-4b43-fafd-f8f59e450d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = np.arange(132, 144, 1)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[132 133 134 135 136 137 138 139 140 141 142 143]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIgh5krLJpf6",
        "colab_type": "code",
        "outputId": "742384a3-1ade-43ac-d76b-bb6f95e64044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "plt.title('Month vs Passenger')\n",
        "plt.ylabel('Total Passengers')\n",
        "plt.grid(True)\n",
        "plt.autoscale(axis='x', tight=True)\n",
        "plt.plot(flight_data['passengers'])\n",
        "plt.plot(x,actual_predictions)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAE/CAYAAAD/m9qwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC4mAkhWJutL",
        "colab_type": "code",
        "outputId": "9b35c832-e5a4-4dc0-c966-274633d7e059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "plt.title('Month vs Passenger')\n",
        "plt.ylabel('Total Passengers')\n",
        "plt.grid(True)\n",
        "plt.autoscale(axis='x', tight=True)\n",
        "\n",
        "plt.plot(flight_data['passengers'][-train_window:])\n",
        "plt.plot(x,actual_predictions)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAE/CAYAAAD/m9qwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4oFU7ImIiIiIiHig/w9oR717fptc1QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XthNJI2Gk7ff",
        "colab_type": "code",
        "outputId": "f803411b-0301-4aa3-83c2-41273cb963ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "x = torch.randn(3, 4, 2)\n",
        "z = x.view(-1, 12)\n",
        "print(x)\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-1.2754,  1.3643],\n",
            "         [ 1.4715,  0.3119],\n",
            "         [-0.0647,  1.6933],\n",
            "         [-0.7259,  0.6605]],\n",
            "\n",
            "        [[-0.1287,  0.0146],\n",
            "         [-1.5691, -0.7520],\n",
            "         [ 1.2978,  0.4714],\n",
            "         [-1.3272,  0.4786]],\n",
            "\n",
            "        [[-0.5141,  0.3718],\n",
            "         [ 2.1118,  0.2591],\n",
            "         [ 1.2284, -0.6123],\n",
            "         [ 0.0856, -1.2629]]])\n",
            "tensor([[-1.2754,  1.3643,  1.4715,  0.3119, -0.0647,  1.6933, -0.7259,  0.6605,\n",
            "         -0.1287,  0.0146, -1.5691, -0.7520],\n",
            "        [ 1.2978,  0.4714, -1.3272,  0.4786, -0.5141,  0.3718,  2.1118,  0.2591,\n",
            "          1.2284, -0.6123,  0.0856, -1.2629]])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}